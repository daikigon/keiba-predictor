{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ç«¶é¦¬äºˆæƒ³ã‚¢ãƒ—ãƒª - ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° & äºˆæ¸¬\n\nã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯Google Colabã§å®Ÿè¡Œã—ã€ä»¥ä¸‹ã‚’è¡Œã„ã¾ã™ï¼š\n1. ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°\n2. äºˆæ¸¬ã®å®Ÿè¡Œ\n3. Supabaseã¸ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆDatabase + Storageï¼‰\n\n## ä½¿ç”¨æ–¹æ³•\n1. å·¦ä¸Šã®ã€Œãƒ•ã‚¡ã‚¤ãƒ«ã€â†’ã€Œãƒ‰ãƒ©ã‚¤ãƒ–ã«ã‚³ãƒ”ãƒ¼ã€ã§ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ\n2. å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ğŸ”‘ã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã«ä»¥ä¸‹ã‚’è¨­å®šï¼š\n   - `SUPABASE_URL`\n   - `SUPABASE_KEY`\n3. Supabaseãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ Storage ã« `models` ãƒã‚±ãƒƒãƒˆã‚’ä½œæˆ\n4. ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œ\n\n## å¿…è¦ãªã‚‚ã®\n- Supabaseã‚¢ã‚«ã‚¦ãƒ³ãƒˆï¼ˆç„¡æ–™ãƒ—ãƒ©ãƒ³ã§OKï¼‰\n- Google Colabã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã«è¨­å®šã—ãŸèªè¨¼æƒ…å ±"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install -q supabase requests beautifulsoup4 lxml pandas numpy lightgbm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Supabaseèªè¨¼æƒ…å ±ã®è¨­å®š\n# Google Colabã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’ä½¿ç”¨\ntry:\n    from google.colab import userdata\n    SUPABASE_URL = userdata.get('SUPABASE_URL')\n    SUPABASE_KEY = userdata.get('SUPABASE_KEY')\n    print(\"Colabã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ\")\nexcept:\n    # ç›´æ¥å…¥åŠ›ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰\n    SUPABASE_URL = \"https://your-project.supabase.co\"  # @param {type:\"string\"}\n    SUPABASE_KEY = \"your-service-role-key\"  # @param {type:\"string\"}\n    print(\"æ‰‹å‹•å…¥åŠ›ã®èªè¨¼æƒ…å ±ã‚’ä½¿ç”¨ã—ã¾ã™\")\n\n# æ¥ç¶šãƒ†ã‚¹ãƒˆ\nfrom supabase import create_client\nsupabase = create_client(SUPABASE_URL, SUPABASE_KEY)\nprint(f\"Supabaseæ¥ç¶š: {SUPABASE_URL[:30]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã®å®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š\n",
    "SCRAPE_INTERVAL = 1.5  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ï¼ˆç§’ï¼‰\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"ja,en-US;q=0.9,en;q=0.8\",\n",
    "}\n",
    "\n",
    "# JRAç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰\n",
    "JRA_COURSE_CODES = {\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\"}\n",
    "COURSE_NAMES = {\n",
    "    \"01\": \"æœ­å¹Œ\", \"02\": \"å‡½é¤¨\", \"03\": \"ç¦å³¶\", \"04\": \"æ–°æ½Ÿ\",\n",
    "    \"05\": \"æ±äº¬\", \"06\": \"ä¸­å±±\", \"07\": \"ä¸­äº¬\", \"08\": \"äº¬éƒ½\",\n",
    "    \"09\": \"é˜ªç¥\", \"10\": \"å°å€‰\",\n",
    "}\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "last_request_time = 0\n",
    "\n",
    "def fetch_html(url: str) -> str:\n",
    "    \"\"\"HTMLã‚’å–å¾—ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãï¼‰\"\"\"\n",
    "    global last_request_time\n",
    "    elapsed = time.time() - last_request_time\n",
    "    if elapsed < SCRAPE_INTERVAL:\n",
    "        time.sleep(SCRAPE_INTERVAL - elapsed)\n",
    "    \n",
    "    response = session.get(url, timeout=30)\n",
    "    last_request_time = time.time()\n",
    "    \n",
    "    if \"EUC-JP\" in response.text[:500] or \"euc-jp\" in response.text[:500].lower():\n",
    "        response.encoding = \"euc-jp\"\n",
    "    else:\n",
    "        response.encoding = response.apparent_encoding or \"utf-8\"\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "def is_jra_race(race_id: str) -> bool:\n",
    "    \"\"\"JRAãƒ¬ãƒ¼ã‚¹ã‹ã©ã†ã‹åˆ¤å®š\"\"\"\n",
    "    if len(race_id) >= 6:\n",
    "        return race_id[4:6] in JRA_COURSE_CODES\n",
    "    return False\n",
    "\n",
    "print(\"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_race_list(target_date: date, jra_only: bool = True) -> List[Dict]:\n",
    "    \"\"\"æŒ‡å®šæ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—\"\"\"\n",
    "    date_str = target_date.strftime(\"%Y%m%d\")\n",
    "    url = f\"https://db.netkeiba.com/race/list/{date_str}/\"\n",
    "    \n",
    "    html = fetch_html(url)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    races = []\n",
    "    seen_ids = set()\n",
    "    \n",
    "    for link in soup.find_all(\"a\", href=True):\n",
    "        href = link.get(\"href\", \"\")\n",
    "        match = re.search(r\"/race/(\\d{12})/\", href)\n",
    "        if match:\n",
    "            race_id = match.group(1)\n",
    "            if race_id not in seen_ids:\n",
    "                if jra_only and not is_jra_race(race_id):\n",
    "                    continue\n",
    "                seen_ids.add(race_id)\n",
    "                races.append({\n",
    "                    \"race_id\": race_id,\n",
    "                    \"date\": target_date.isoformat(),\n",
    "                    \"race_name\": link.get_text(strip=True),\n",
    "                })\n",
    "    \n",
    "    return races\n",
    "\n",
    "def scrape_race_detail(race_id: str) -> Dict:\n",
    "    \"\"\"ãƒ¬ãƒ¼ã‚¹è©³ç´°ã‚’å–å¾—\"\"\"\n",
    "    url = f\"https://db.netkeiba.com/race/{race_id}/\"\n",
    "    html = fetch_html(url)\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # ãƒ¬ãƒ¼ã‚¹æƒ…å ±\n",
    "    race_data = {\n",
    "        \"race_id\": race_id,\n",
    "        \"course\": COURSE_NAMES.get(race_id[4:6], \"\"),\n",
    "        \"race_number\": int(race_id[10:12]) if len(race_id) >= 12 else 0,\n",
    "    }\n",
    "    \n",
    "    # ãƒ¬ãƒ¼ã‚¹å\n",
    "    title_elem = soup.select_one(\".racedata h1, .data_intro h1\")\n",
    "    if title_elem:\n",
    "        race_data[\"race_name\"] = title_elem.get_text(strip=True)\n",
    "    \n",
    "    # è·é›¢ãƒ»é¦¬å ´\n",
    "    race_data_elem = soup.select_one(\".racedata, .data_intro\")\n",
    "    if race_data_elem:\n",
    "        text = race_data_elem.get_text()\n",
    "        \n",
    "        distance_match = re.search(r\"(\\d+)m\", text)\n",
    "        if distance_match:\n",
    "            race_data[\"distance\"] = int(distance_match.group(1))\n",
    "        \n",
    "        if \"èŠ\" in text:\n",
    "            race_data[\"track_type\"] = \"èŠ\"\n",
    "        elif \"ãƒ€ãƒ¼ãƒˆ\" in text or \"ãƒ€\" in text:\n",
    "            race_data[\"track_type\"] = \"ãƒ€ãƒ¼ãƒˆ\"\n",
    "        \n",
    "        condition_match = re.search(r\"(èŠ|ãƒ€)\\s*:\\s*(è‰¯|ç¨é‡|é‡|ä¸è‰¯)\", text)\n",
    "        if condition_match:\n",
    "            race_data[\"condition\"] = condition_match.group(2)\n",
    "        \n",
    "        for grade in [\"(G1)\", \"(G2)\", \"(G3)\", \"(L)\", \"ã‚ªãƒ¼ãƒ—ãƒ³\", \"3å‹\", \"2å‹\", \"1å‹\", \"æ–°é¦¬\", \"æœªå‹åˆ©\"]:\n",
    "            if grade in text:\n",
    "                race_data[\"grade\"] = grade.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "                break\n",
    "    \n",
    "    # å‡ºèµ°é¦¬\n",
    "    entries = []\n",
    "    table = soup.select_one(\"table.race_table_01\")\n",
    "    if table:\n",
    "        for row in table.select(\"tr\")[1:]:\n",
    "            entry = parse_entry_row(row)\n",
    "            if entry:\n",
    "                entries.append(entry)\n",
    "    \n",
    "    race_data[\"entries\"] = entries\n",
    "    return race_data\n",
    "\n",
    "def parse_entry_row(row) -> Optional[Dict]:\n",
    "    \"\"\"å‡ºèµ°é¦¬ã®è¡Œã‚’ãƒ‘ãƒ¼ã‚¹\"\"\"\n",
    "    cells = row.select(\"td\")\n",
    "    if len(cells) < 10:\n",
    "        return None\n",
    "    \n",
    "    entry = {}\n",
    "    \n",
    "    # ç€é †\n",
    "    try:\n",
    "        result_text = cells[0].get_text(strip=True)\n",
    "        if result_text.isdigit():\n",
    "            entry[\"result\"] = int(result_text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # æ ç•ª\n",
    "    try:\n",
    "        entry[\"frame_number\"] = int(cells[1].get_text(strip=True))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # é¦¬ç•ª\n",
    "    try:\n",
    "        entry[\"horse_number\"] = int(cells[2].get_text(strip=True))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    # é¦¬åãƒ»ID\n",
    "    horse_link = cells[3].select_one(\"a\")\n",
    "    if horse_link:\n",
    "        href = horse_link.get(\"href\", \"\")\n",
    "        match = re.search(r\"/horse/(\\d+)\", href)\n",
    "        if match:\n",
    "            entry[\"horse_id\"] = match.group(1)\n",
    "        entry[\"horse_name\"] = horse_link.get_text(strip=True)\n",
    "    \n",
    "    # æ€§é½¢\n",
    "    try:\n",
    "        sex_age = cells[4].get_text(strip=True)\n",
    "        if sex_age:\n",
    "            entry[\"sex\"] = sex_age[0]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # æ–¤é‡\n",
    "    try:\n",
    "        entry[\"weight\"] = float(cells[5].get_text(strip=True))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # é¨æ‰‹\n",
    "    jockey_link = cells[6].select_one(\"a\")\n",
    "    if jockey_link:\n",
    "        href = jockey_link.get(\"href\", \"\")\n",
    "        match = re.search(r\"/jockey/(?:result/recent/)?(\\d+)\", href)\n",
    "        if match:\n",
    "            entry[\"jockey_id\"] = match.group(1)\n",
    "        entry[\"jockey_name\"] = jockey_link.get_text(strip=True)\n",
    "    \n",
    "    # ã‚¿ã‚¤ãƒ \n",
    "    try:\n",
    "        time_text = cells[7].get_text(strip=True)\n",
    "        if time_text:\n",
    "            entry[\"finish_time\"] = time_text\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # ã‚ªãƒƒã‚º\n",
    "    try:\n",
    "        if len(cells) > 12:\n",
    "            odds_text = cells[12].get_text(strip=True)\n",
    "            if odds_text:\n",
    "                entry[\"odds\"] = float(odds_text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # äººæ°—\n",
    "    try:\n",
    "        if len(cells) > 13:\n",
    "            pop_text = cells[13].get_text(strip=True)\n",
    "            if pop_text.isdigit():\n",
    "                entry[\"popularity\"] = int(pop_text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return entry if entry.get(\"horse_number\") else None\n",
    "\n",
    "print(\"ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Supabaseä¿å­˜é–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_horse(horse_data: Dict) -> bool:\n",
    "    \"\"\"é¦¬ã‚’Supabaseã«ä¿å­˜\"\"\"\n",
    "    try:\n",
    "        # æ—¢å­˜ãƒã‚§ãƒƒã‚¯\n",
    "        existing = supabase.table(\"horses\").select(\"horse_id\").eq(\"horse_id\", horse_data[\"horse_id\"]).execute()\n",
    "        \n",
    "        if existing.data:\n",
    "            supabase.table(\"horses\").update(horse_data).eq(\"horse_id\", horse_data[\"horse_id\"]).execute()\n",
    "        else:\n",
    "            supabase.table(\"horses\").insert(horse_data).execute()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"é¦¬ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return False\n",
    "\n",
    "def save_jockey(jockey_data: Dict) -> bool:\n",
    "    \"\"\"é¨æ‰‹ã‚’Supabaseã«ä¿å­˜\"\"\"\n",
    "    try:\n",
    "        existing = supabase.table(\"jockeys\").select(\"jockey_id\").eq(\"jockey_id\", jockey_data[\"jockey_id\"]).execute()\n",
    "        \n",
    "        if existing.data:\n",
    "            supabase.table(\"jockeys\").update(jockey_data).eq(\"jockey_id\", jockey_data[\"jockey_id\"]).execute()\n",
    "        else:\n",
    "            supabase.table(\"jockeys\").insert(jockey_data).execute()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"é¨æ‰‹ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return False\n",
    "\n",
    "def save_race(race_data: Dict) -> bool:\n",
    "    \"\"\"ãƒ¬ãƒ¼ã‚¹ã‚’Supabaseã«ä¿å­˜\"\"\"\n",
    "    try:\n",
    "        entries = race_data.pop(\"entries\", [])\n",
    "        \n",
    "        # ãƒ¬ãƒ¼ã‚¹ä¿å­˜\n",
    "        existing = supabase.table(\"races\").select(\"race_id\").eq(\"race_id\", race_data[\"race_id\"]).execute()\n",
    "        \n",
    "        if existing.data:\n",
    "            supabase.table(\"races\").update(race_data).eq(\"race_id\", race_data[\"race_id\"]).execute()\n",
    "        else:\n",
    "            supabase.table(\"races\").insert(race_data).execute()\n",
    "        \n",
    "        # å‡ºèµ°é¦¬ä¿å­˜\n",
    "        for entry in entries:\n",
    "            # é¦¬ã‚’ä¿å­˜\n",
    "            if \"horse_id\" in entry:\n",
    "                horse_data = {\n",
    "                    \"horse_id\": entry[\"horse_id\"],\n",
    "                    \"name\": entry.get(\"horse_name\", \"ä¸æ˜\"),\n",
    "                    \"sex\": entry.get(\"sex\", \"ä¸\"),\n",
    "                    \"birth_year\": 2020,  # ä»®\n",
    "                }\n",
    "                save_horse(horse_data)\n",
    "            \n",
    "            # é¨æ‰‹ã‚’ä¿å­˜\n",
    "            if \"jockey_id\" in entry:\n",
    "                jockey_data = {\n",
    "                    \"jockey_id\": entry[\"jockey_id\"],\n",
    "                    \"name\": entry.get(\"jockey_name\", \"ä¸æ˜\"),\n",
    "                }\n",
    "                save_jockey(jockey_data)\n",
    "            \n",
    "            # å‡ºèµ°é¦¬ä¿å­˜\n",
    "            entry_data = {\n",
    "                \"race_id\": race_data[\"race_id\"],\n",
    "                \"horse_id\": entry.get(\"horse_id\"),\n",
    "                \"jockey_id\": entry.get(\"jockey_id\"),\n",
    "                \"frame_number\": entry.get(\"frame_number\"),\n",
    "                \"horse_number\": entry[\"horse_number\"],\n",
    "                \"weight\": entry.get(\"weight\"),\n",
    "                \"odds\": entry.get(\"odds\"),\n",
    "                \"popularity\": entry.get(\"popularity\"),\n",
    "                \"result\": entry.get(\"result\"),\n",
    "                \"finish_time\": entry.get(\"finish_time\"),\n",
    "            }\n",
    "            \n",
    "            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯\n",
    "            existing = supabase.table(\"entries\").select(\"id\").eq(\"race_id\", race_data[\"race_id\"]).eq(\"horse_number\", entry[\"horse_number\"]).execute()\n",
    "            \n",
    "            if existing.data:\n",
    "                supabase.table(\"entries\").update(entry_data).eq(\"id\", existing.data[0][\"id\"]).execute()\n",
    "            else:\n",
    "                supabase.table(\"entries\").insert(entry_data).execute()\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ãƒ¬ãƒ¼ã‚¹ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"Supabaseä¿å­˜é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¾è±¡æ—¥ã‚’è¨­å®š\n",
    "target_date = date.today()  # ä»Šæ—¥\n",
    "# target_date = date(2024, 12, 22)  # ç‰¹å®šã®æ—¥ä»˜\n",
    "\n",
    "print(f\"å¯¾è±¡æ—¥: {target_date}\")\n",
    "print(f\"JRAãƒ¬ãƒ¼ã‚¹ã®ã¿å–å¾—ã—ã¾ã™\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—\n",
    "races = scrape_race_list(target_date, jra_only=True)\n",
    "print(f\"\\n{len(races)}ä»¶ã®ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "\n",
    "for race in races[:5]:  # æœ€åˆã®5ä»¶ã‚’è¡¨ç¤º\n",
    "    print(f\"  - {race['race_id']}: {race['race_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…¨ãƒ¬ãƒ¼ã‚¹ã®è©³ç´°ã‚’å–å¾—ã—ã¦ä¿å­˜\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for race_info in tqdm(races, desc=\"ãƒ¬ãƒ¼ã‚¹å–å¾—ä¸­\"):\n",
    "    try:\n",
    "        race_detail = scrape_race_detail(race_info[\"race_id\"])\n",
    "        race_detail[\"date\"] = race_info[\"date\"]\n",
    "        \n",
    "        if save_race(race_detail):\n",
    "            success_count += 1\n",
    "        else:\n",
    "            error_count += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nã‚¨ãƒ©ãƒ¼: {race_info['race_id']} - {e}\")\n",
    "        error_count += 1\n",
    "\n",
    "print(f\"\\nå®Œäº†: æˆåŠŸ {success_count}ä»¶, ã‚¨ãƒ©ãƒ¼ {error_count}ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†ï¼ˆSupabase Storageï¼‰\n\nå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯Supabase Storageã«ä¿å­˜ã—ã¾ã™ã€‚\n\n### äº‹å‰æº–å‚™\n**Supabaseãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ãƒã‚±ãƒƒãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š**\n1. Storage â†’ New bucket\n2. Name: `models`\n3. Public bucket: OFFï¼ˆãƒã‚§ãƒƒã‚¯ã‚’å¤–ã™ï¼‰\n4. Create bucket"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Supabase Storageã®ãƒã‚±ãƒƒãƒˆè¨­å®š\nBUCKET_NAME = \"models\"\nMODEL_FILENAME = \"model_v1.pkl\"\n\n# ãƒã‚±ãƒƒãƒˆç¢ºèª\n# â€»ãƒã‚±ãƒƒãƒˆã¯Supabaseãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§äº‹å‰ã«ä½œæˆã—ã¦ãã ã•ã„\n#   Storage â†’ New bucket â†’ Name: \"models\" â†’ Public: OFF\ntry:\n    files = supabase.storage.from_(BUCKET_NAME).list()\n    print(f\"âœ“ ãƒã‚±ãƒƒãƒˆ '{BUCKET_NAME}' ã«æ¥ç¶šã—ã¾ã—ãŸ\")\n    print(f\"  ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(files)}\")\nexcept Exception as e:\n    print(f\"âœ— ãƒã‚±ãƒƒãƒˆ '{BUCKET_NAME}' ã«æ¥ç¶šã§ãã¾ã›ã‚“\")\n    print(f\"  ã‚¨ãƒ©ãƒ¼: {e}\")\n    print(f\"\\nã€å¯¾å‡¦æ³•ã€‘Supabaseãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ãƒã‚±ãƒƒãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„:\")\n    print(f\"  1. Storage â†’ New bucket\")\n    print(f\"  2. Name: models\")\n    print(f\"  3. Public bucket: OFF\")\n    print(f\"  4. Create bucket\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pickle\nimport pandas as pd\nimport numpy as np\nimport io\n\ndef upload_model(model, filename: str = MODEL_FILENAME) -> bool:\n    \"\"\"ãƒ¢ãƒ‡ãƒ«ã‚’Supabase Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\"\"\"\n    try:\n        # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›\n        buffer = io.BytesIO()\n        pickle.dump(model, buffer)\n        buffer.seek(0)\n        \n        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n        supabase.storage.from_(BUCKET_NAME).upload(\n            filename,\n            buffer.getvalue(),\n            file_options={\"content-type\": \"application/octet-stream\", \"upsert\": \"true\"}\n        )\n        print(f\"ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {filename}\")\n        return True\n    except Exception as e:\n        print(f\"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n        return False\n\ndef download_model(filename: str = MODEL_FILENAME):\n    \"\"\"ãƒ¢ãƒ‡ãƒ«ã‚’Supabase Storageã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\"\"\"\n    try:\n        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n        response = supabase.storage.from_(BUCKET_NAME).download(filename)\n        \n        # ãƒã‚¤ãƒˆåˆ—ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å¾©å…ƒ\n        buffer = io.BytesIO(response)\n        model = pickle.load(buffer)\n        print(f\"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {filename}\")\n        return model\n    except Exception as e:\n        print(f\"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n        return None\n\ndef list_models() -> list:\n    \"\"\"ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—\"\"\"\n    try:\n        files = supabase.storage.from_(BUCKET_NAME).list()\n        models = [f[\"name\"] for f in files if f[\"name\"].endswith(\".pkl\")]\n        print(f\"ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: {models}\")\n        return models\n    except Exception as e:\n        print(f\"ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n        return []\n\ndef save_prediction(race_id: str, results: Dict) -> bool:\n    \"\"\"äºˆæ¸¬çµæœã‚’Supabaseã«ä¿å­˜\"\"\"\n    try:\n        prediction_data = {\n            \"race_id\": race_id,\n            \"model_version\": MODEL_FILENAME.replace(\".pkl\", \"\"),\n            \"results_json\": results,\n        }\n        supabase.table(\"predictions\").insert(prediction_data).execute()\n        return True\n    except Exception as e:\n        print(f\"äºˆæ¸¬ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\")\n        return False\n\nprint(\"Supabase Storageé–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")\nprint(\"  - upload_model(model): ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\nprint(\"  - download_model(): ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\")\nprint(\"  - list_models(): ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒ‡ãƒ¼ã‚¿ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supabaseã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’ç¢ºèª\n",
    "tables = [\"races\", \"entries\", \"horses\", \"jockeys\", \"predictions\"]\n",
    "\n",
    "print(\"Supabaseãƒ‡ãƒ¼ã‚¿ä»¶æ•°:\")\n",
    "for table in tables:\n",
    "    try:\n",
    "        result = supabase.table(table).select(\"*\", count=\"exact\").execute()\n",
    "        print(f\"  {table}: {result.count}ä»¶\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {table}: ã‚¨ãƒ©ãƒ¼ - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»Šæ—¥ã®ãƒ¬ãƒ¼ã‚¹ã‚’ç¢ºèª\n",
    "today = date.today().isoformat()\n",
    "result = supabase.table(\"races\").select(\"*\").eq(\"date\", today).execute()\n",
    "\n",
    "print(f\"\\n{today}ã®ãƒ¬ãƒ¼ã‚¹: {len(result.data)}ä»¶\")\n",
    "for race in result.data:\n",
    "    print(f\"  - {race['race_id']}: {race['course']} {race['race_number']}R {race.get('race_name', '')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ä½¿ã„æ–¹ã®ã¾ã¨ã‚\n\n### æ—¥å¸¸ã®é‹ç”¨\n\n1. **æ¯æ—¥ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°**: ã‚»ã‚¯ã‚·ãƒ§ãƒ³1ã€œ4ã‚’å®Ÿè¡Œ\n2. **ãƒ‡ãƒ¼ã‚¿ç¢ºèª**: ã‚»ã‚¯ã‚·ãƒ§ãƒ³6ã‚’å®Ÿè¡Œ\n\n### ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†ï¼ˆSupabase Storageï¼‰\n\n```python\n# ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\nupload_model(trained_model, \"model_v2.pkl\")\n\n# ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\nmodel = download_model(\"model_v2.pkl\")\n\n# ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§\nlist_models()\n```\n\n### äºˆæ¸¬ã®å®Ÿè¡Œï¼ˆãƒ¢ãƒ‡ãƒ«å­¦ç¿’å¾Œï¼‰\n\n```python\n# ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\nmodel = download_model()\n\n# äºˆæ¸¬ã‚’å®Ÿè¡Œ\npredictions = model.predict(features)\n\n# çµæœã‚’ä¿å­˜\nsave_prediction(race_id, {\"predictions\": predictions.tolist()})\n```\n\n### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Google Colab   â”‚\nâ”‚  - ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° â”‚\nâ”‚  - äºˆæ¸¬å®Ÿè¡Œ      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚    Supabase     â”‚\nâ”‚  - Database     â”‚ â† ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿\nâ”‚  - Storage      â”‚ â† å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«\nâ”‚  - Auth         â”‚ â† ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     Vercel      â”‚\nâ”‚  - Frontend     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
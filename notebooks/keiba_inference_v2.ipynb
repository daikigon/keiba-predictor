{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ç«¶é¦¬äºˆæƒ³ã‚¢ãƒ—ãƒª - å½“æ—¥äºˆæ¸¬ v2\n\n**æœ€çµ‚æ›´æ–°: 2026-01-17 10:45ï¼ˆPlaywright + nest_asyncioå¯¾å¿œç‰ˆï¼‰**\n\n---\n\n**Option B: äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä½¿ç”¨**\n\n## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n\n```\nã€äº‹å‰æº–å‚™ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«PC - é€±1å›ï¼‰ã€‘\n1. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ â†’ Supabase Storage ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n2. ç‰¹å¾´é‡è¨ˆç®— â†’ Supabase DB (horse_features) ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n\nã€å½“æ—¥äºˆæ¸¬ï¼ˆã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ - ã‚¹ãƒãƒ›ã‹ã‚‰OKï¼‰ã€‘\n1. Supabase Storage ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n2. netkeiba ã‹ã‚‰å½“æ—¥ã®å‡ºé¦¬è¡¨ã‚’å–å¾—\n3. Supabase DB ã‹ã‚‰äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’å–å¾—\n4. ãƒ¬ãƒ¼ã‚¹å›ºæœ‰ã®ç‰¹å¾´é‡ã‚’è¨ˆç®—\n5. äºˆæ¸¬å®Ÿè¡Œãƒ»çµæœè¡¨ç¤º\n```\n\n## ä½¿ç”¨æ–¹æ³•\n1. å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ğŸ”‘ã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã«ä»¥ä¸‹ã‚’è¨­å®šï¼š\n   - `SUPABASE_URL`\n   - `SUPABASE_KEY`\n2. ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œ"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install -q supabase requests beautifulsoup4 lxml pandas numpy lightgbm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supabaseèªè¨¼æƒ…å ±ã®è¨­å®š\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    SUPABASE_URL = userdata.get('SUPABASE_URL')\n",
    "    SUPABASE_KEY = userdata.get('SUPABASE_KEY')\n",
    "    print(\"âœ“ Colabã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ\")\n",
    "except:\n",
    "    # ç›´æ¥å…¥åŠ›ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰\n",
    "    SUPABASE_URL = \"https://your-project.supabase.co\"  # @param {type:\"string\"}\n",
    "    SUPABASE_KEY = \"your-service-role-key\"  # @param {type:\"string\"}\n",
    "    print(\"âš  æ‰‹å‹•å…¥åŠ›ã®èªè¨¼æƒ…å ±ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "# æ¥ç¶šãƒ†ã‚¹ãƒˆ\n",
    "from supabase import create_client\n",
    "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "print(f\"âœ“ Supabaseæ¥ç¶š: {SUPABASE_URL[:40]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BUCKET_NAME = \"models\"\n",
    "\n",
    "def list_available_models():\n",
    "    \"\"\"åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—\"\"\"\n",
    "    try:\n",
    "        files = supabase.storage.from_(BUCKET_NAME).list()\n",
    "        models = [f[\"name\"] for f in files if f[\"name\"].endswith(\".pkl\")]\n",
    "        print(f\"åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {models}\")\n",
    "        return models\n",
    "    except Exception as e:\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_model(version: str = \"v1\"):\n",
    "    \"\"\"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\"\"\"\n",
    "    filename = f\"model_{version}.pkl\"\n",
    "    print(f\"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {filename}\")\n",
    "\n",
    "    try:\n",
    "        response = supabase.storage.from_(BUCKET_NAME).download(filename)\n",
    "        buffer = io.BytesIO(response)\n",
    "        model_data = pickle.load(buffer)\n",
    "        print(f\"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ\")\n",
    "        print(f\"  ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {model_data.get('model_version', 'unknown')}\")\n",
    "        print(f\"  ç‰¹å¾´é‡æ•°: {len(model_data.get('feature_columns', []))}\")\n",
    "        return model_data\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}\")\n",
    "        return None\n",
    "\n",
    "# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º\n",
    "list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "MODEL_VERSION = \"v1\"  # @param {type:\"string\"}\n",
    "\n",
    "model_data = download_model(MODEL_VERSION)\n",
    "\n",
    "if model_data:\n",
    "    model = model_data[\"model\"]\n",
    "    scaler = model_data[\"scaler\"]\n",
    "    calibrator = model_data.get(\"calibrator\")\n",
    "    feature_columns = model_data[\"feature_columns\"]\n",
    "    print(f\"\\nâœ“ ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†ï¼ˆ{len(feature_columns)}ç‰¹å¾´é‡ï¼‰\")\n",
    "else:\n",
    "    print(\"\\nâœ— ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "    print(\"ãƒ­ãƒ¼ã‚«ãƒ«FastAPIã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä»¶æ•°ã‚’ç¢ºèª\n",
    "try:\n",
    "    horse_result = supabase.table(\"horse_features\").select(\"id\", count=\"exact\").execute()\n",
    "    jockey_result = supabase.table(\"jockey_features\").select(\"id\", count=\"exact\").execute()\n",
    "\n",
    "    print(f\"âœ“ horse_features: {horse_result.count}ä»¶\")\n",
    "    print(f\"âœ“ jockey_features: {jockey_result.count}ä»¶\")\n",
    "\n",
    "    if horse_result.count == 0:\n",
    "        print(\"\\nâš  ç‰¹å¾´é‡ãŒåŒæœŸã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼\")\n",
    "        print(\"ãƒ­ãƒ¼ã‚«ãƒ«FastAPIã§ POST /api/v1/model/sync-features ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    print(\"Supabaseã§ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ003_horse_features.sqlï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å½“æ—¥ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import requests\nimport time\nimport re\nfrom datetime import date, datetime, timedelta\nfrom bs4 import BeautifulSoup\nfrom typing import Optional, List, Dict\n\n# ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•åŒ–è¨­å®šï¼ˆColabç”¨ï¼‰\nUSE_BROWSER = True  # @param {type:\"boolean\"} Playwrightã§ã‚ªãƒƒã‚ºã‚’å–å¾—\n\n# Playwrightï¼ˆãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•åŒ–ï¼‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\nplaywright_instance = None\nplaywright_browser = None\nplaywright_context = None\n\nif USE_BROWSER:\n    print(\"Playwrightç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...\")\n    \n    # nest_asyncioã§Colabã®asyncioç’°å¢ƒã¨å…±å­˜ã•ã›ã‚‹\n    !pip install -q playwright nest_asyncio\n    !playwright install chromium\n    \n    import nest_asyncio\n    nest_asyncio.apply()\n    \n    from playwright.sync_api import sync_playwright\n    \n    def get_browser_page():\n        \"\"\"Playwrightã®ãƒ–ãƒ©ã‚¦ã‚¶ãƒšãƒ¼ã‚¸ã‚’å–å¾—\"\"\"\n        global playwright_instance, playwright_browser, playwright_context\n        \n        if playwright_browser is None:\n            playwright_instance = sync_playwright().start()\n            playwright_browser = playwright_instance.chromium.launch(\n                headless=True,\n                args=[\n                    '--no-sandbox',\n                    '--disable-dev-shm-usage',\n                    '--disable-gpu',\n                ]\n            )\n            playwright_context = playwright_browser.new_context(\n                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n            )\n        \n        return playwright_context.new_page()\n    \n    def close_browser():\n        \"\"\"ãƒ–ãƒ©ã‚¦ã‚¶ã‚’çµ‚äº†\"\"\"\n        global playwright_instance, playwright_browser, playwright_context\n        if playwright_context:\n            playwright_context.close()\n            playwright_context = None\n        if playwright_browser:\n            playwright_browser.close()\n            playwright_browser = None\n        if playwright_instance:\n            playwright_instance.stop()\n            playwright_instance = None\n    \n    # å‹•ä½œç¢ºèª\n    try:\n        test_page = get_browser_page()\n        test_page.goto(\"https://www.google.com\", timeout=30000)\n        title = test_page.title()\n        test_page.close()\n        print(f\"âœ“ Playwrightæº–å‚™å®Œäº†ï¼ˆãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸: {title}ï¼‰\")\n    except Exception as e:\n        print(f\"âš  PlaywrightåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}\")\n        print(\"â†’ USE_BROWSER = False ã«è¨­å®šã—ã¦APIãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™\")\n        USE_BROWSER = False\n        close_browser()\n\n# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š\nSCRAPE_INTERVAL = 1.5\nHEADERS = {\n    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\",\n    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n}\n\nJRA_COURSE_CODES = {\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\"}\nCOURSE_NAMES = {\n    \"01\": \"æœ­å¹Œ\", \"02\": \"å‡½é¤¨\", \"03\": \"ç¦å³¶\", \"04\": \"æ–°æ½Ÿ\",\n    \"05\": \"æ±äº¬\", \"06\": \"ä¸­å±±\", \"07\": \"ä¸­äº¬\", \"08\": \"äº¬éƒ½\",\n    \"09\": \"é˜ªç¥\", \"10\": \"å°å€‰\",\n}\n\nsession = requests.Session()\nsession.headers.update(HEADERS)\nlast_request_time = 0\n\ndef fetch_html(url: str) -> str:\n    global last_request_time\n    elapsed = time.time() - last_request_time\n    if elapsed < SCRAPE_INTERVAL:\n        time.sleep(SCRAPE_INTERVAL - elapsed)\n\n    response = session.get(url, timeout=30)\n    last_request_time = time.time()\n\n    if \"EUC-JP\" in response.text[:500] or \"euc-jp\" in response.text[:500].lower():\n        response.encoding = \"euc-jp\"\n    else:\n        response.encoding = response.apparent_encoding or \"utf-8\"\n\n    return response.text\n\ndef is_jra_race(race_id: str) -> bool:\n    if len(race_id) >= 6:\n        return race_id[4:6] in JRA_COURSE_CODES\n    return False\n\nprint(\"âœ“ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def scrape_race_list(target_date: date, jra_only: bool = True) -> List[Dict]:\n    \"\"\"æŒ‡å®šæ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ï¼ˆrace_list_sub.htmlã‚’ä½¿ç”¨ï¼‰\"\"\"\n    date_str = target_date.strftime(\"%Y%m%d\")\n    url = f\"https://race.netkeiba.com/top/race_list_sub.html?kaisai_date={date_str}\"\n\n    html = fetch_html(url)\n    soup = BeautifulSoup(html, \"lxml\")\n\n    races = []\n    seen_ids = set()\n\n    for link in soup.find_all(\"a\", href=True):\n        href = link.get(\"href\", \"\")\n        match = re.search(r\"race_id=(\\d{12})\", href)\n        if match:\n            race_id = match.group(1)\n            if race_id not in seen_ids:\n                if jra_only and not is_jra_race(race_id):\n                    continue\n                seen_ids.add(race_id)\n                races.append({\n                    \"race_id\": race_id,\n                    \"date\": target_date.isoformat(),\n                    \"race_name\": link.get_text(strip=True),\n                })\n\n    races.sort(key=lambda x: x[\"race_id\"])\n    return races\n\n\ndef get_odds_from_api(race_id: str) -> Dict[int, Dict]:\n    \"\"\"APIã‹ã‚‰ã‚ªãƒƒã‚ºã¨äººæ°—ã‚’å–å¾—ï¼ˆå¾“æ¥æ–¹å¼ï¼‰\"\"\"\n    url = f\"https://race.netkeiba.com/api/api_get_jra_odds.html?race_id={race_id}&type=1\"\n    try:\n        response = session.get(url, timeout=10)\n        data = response.json()\n        \n        if data.get(\"status\") != \"result\":\n            return {}\n        \n        odds_data = data.get(\"data\", {}).get(\"odds\", {}).get(\"1\", {})\n        \n        result = {}\n        for umaban, values in odds_data.items():\n            horse_num = int(umaban)\n            result[horse_num] = {\n                \"odds\": float(values[0]) if values[0] else None,\n                \"popularity\": int(values[2]) if values[2] else None,\n            }\n        return result\n    except Exception as e:\n        return {}\n\n\ndef get_odds_with_playwright(race_id: str, page=None) -> Dict[int, Dict]:\n    \"\"\"Playwrightã§ã‚ªãƒƒã‚ºã‚’å–å¾—ï¼ˆJavaScriptå®Ÿè¡Œï¼‰\"\"\"\n    close_page = False\n    if page is None:\n        page = get_browser_page()\n        close_page = True\n    \n    try:\n        url = f\"https://race.netkeiba.com/odds/index.html?race_id={race_id}&type=b1\"\n        page.goto(url, timeout=30000)\n        \n        # ã‚ªãƒƒã‚ºãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã¾ã§å¾…æ©Ÿï¼ˆæœ€å¤§10ç§’ï¼‰\n        try:\n            page.wait_for_function(\n                \"document.querySelector('#odds-1_01')?.textContent !== '---.-'\",\n                timeout=10000\n            )\n        except:\n            pass  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¦ã‚‚ç¶šè¡Œ\n        \n        time.sleep(0.5)  # è¿½åŠ ã®å®‰å®šå¾…æ©Ÿ\n        \n        result = {}\n        # é¦¬ç•ª1ã€œ18ã¾ã§å–å¾—ã‚’è©¦ã¿ã‚‹\n        for i in range(1, 19):\n            try:\n                umaban = f\"{i:02d}\"\n                odds_elem = page.query_selector(f\"#odds-1_{umaban}\")\n                if odds_elem:\n                    odds_text = odds_elem.text_content()\n                    \n                    if odds_text and odds_text != \"---.-\":\n                        # äººæ°—ã‚‚å–å¾—ã‚’è©¦ã¿ã‚‹\n                        try:\n                            row = odds_elem.evaluate(\"el => el.closest('tr')\")\n                            pop_elem = page.query_selector(f\"tr:has(#odds-1_{umaban}) td.Popular span.Num\")\n                            popularity = int(pop_elem.text_content()) if pop_elem and pop_elem.text_content().isdigit() else None\n                        except:\n                            popularity = None\n                        \n                        result[i] = {\n                            \"odds\": float(odds_text),\n                            \"popularity\": popularity,\n                        }\n            except:\n                continue\n        \n        return result\n    except Exception as e:\n        print(f\"Playwright ã‚ªãƒƒã‚ºå–å¾—ã‚¨ãƒ©ãƒ¼ ({race_id}): {e}\")\n        return {}\n    finally:\n        if close_page:\n            page.close()\n\n\ndef scrape_shutuba(race_id: str, page=None) -> Dict:\n    \"\"\"å‡ºé¦¬è¡¨ã‚’å–å¾—ï¼ˆãƒ¬ãƒ¼ã‚¹å‰ã®ãƒ‡ãƒ¼ã‚¿ï¼‰\"\"\"\n    url = f\"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}\"\n    \n    response = session.get(url, timeout=30)\n    if \"EUC-JP\" in response.text[:500] or \"euc-jp\" in response.text[:500].lower():\n        response.encoding = \"euc-jp\"\n    \n    soup = BeautifulSoup(response.text, \"lxml\")\n\n    race_data = {\n        \"race_id\": race_id,\n        \"course\": COURSE_NAMES.get(race_id[4:6], \"\"),\n        \"race_number\": int(race_id[10:12]) if len(race_id) >= 12 else 0,\n    }\n\n    # ãƒ¬ãƒ¼ã‚¹å\n    title_elem = soup.select_one(\".RaceName\")\n    if title_elem:\n        race_data[\"race_name\"] = title_elem.get_text(strip=True)\n\n    # è·é›¢ãƒ»é¦¬å ´\n    race_data_elem = soup.select_one(\".RaceData01\")\n    if race_data_elem:\n        text = race_data_elem.get_text()\n        distance_match = re.search(r\"(\\d+)m\", text)\n        if distance_match:\n            race_data[\"distance\"] = int(distance_match.group(1))\n        if \"èŠ\" in text:\n            race_data[\"track_type\"] = \"èŠ\"\n        elif \"ãƒ€ãƒ¼ãƒˆ\" in text or \"ãƒ€\" in text:\n            race_data[\"track_type\"] = \"ãƒ€ãƒ¼ãƒˆ\"\n\n    # ã‚ªãƒƒã‚ºã‚’å–å¾—ï¼ˆPlaywrightå„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§APIï¼‰\n    odds_data = {}\n    if USE_BROWSER:\n        odds_data = get_odds_with_playwright(race_id, page)\n    \n    if not odds_data:\n        odds_data = get_odds_from_api(race_id)\n    \n    if not odds_data:\n        print(f\"âš  ã‚ªãƒƒã‚ºå–å¾—å¤±æ•—: {race_id} - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤10.0ã‚’ä½¿ç”¨\")\n\n    # å‡ºèµ°é¦¬\n    entries = []\n    for row in soup.select(\"tr.HorseList\"):\n        entry = parse_shutuba_row(row)\n        if entry:\n            horse_num = entry.get(\"horse_number\")\n            if horse_num and horse_num in odds_data:\n                entry[\"odds\"] = odds_data[horse_num][\"odds\"]\n                entry[\"popularity\"] = odds_data[horse_num][\"popularity\"]\n            entries.append(entry)\n\n    race_data[\"entries\"] = entries\n    race_data[\"field_size\"] = len(entries)\n    return race_data\n\n\ndef parse_shutuba_row(row) -> Optional[Dict]:\n    \"\"\"å‡ºé¦¬è¡¨ã®è¡Œã‚’ãƒ‘ãƒ¼ã‚¹\"\"\"\n    entry = {}\n    \n    tds = row.find_all(\"td\")\n    \n    if len(tds) > 0:\n        try:\n            entry[\"frame_number\"] = int(tds[0].get_text(strip=True))\n        except:\n            pass\n\n    if len(tds) > 1:\n        try:\n            entry[\"horse_number\"] = int(tds[1].get_text(strip=True))\n        except:\n            return None\n\n    horse_link = row.select_one(\"span.HorseName a\")\n    if horse_link:\n        href = horse_link.get(\"href\", \"\")\n        match = re.search(r\"/horse/(\\d+)\", href)\n        if match:\n            entry[\"horse_id\"] = match.group(1)\n        entry[\"horse_name\"] = horse_link.get_text(strip=True)\n\n    jockey_td = row.select_one(\"td.Jockey a\")\n    if jockey_td:\n        href = jockey_td.get(\"href\", \"\")\n        match = re.search(r\"/jockey/(?:result/recent/)?(\\d+)\", href)\n        if match:\n            entry[\"jockey_id\"] = match.group(1)\n        entry[\"jockey_name\"] = jockey_td.get_text(strip=True)\n\n    if len(tds) > 5:\n        try:\n            entry[\"weight\"] = float(tds[5].get_text(strip=True))\n        except:\n            pass\n\n    return entry if entry.get(\"horse_number\") else None\n\n\nprint(\"âœ“ å‡ºé¦¬è¡¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸï¼ˆPlaywrightå¯¾å¿œï¼‰\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¾è±¡æ—¥ã‚’è¨­å®š\n",
    "target_date = date.today()  # ä»Šæ—¥\n",
    "# target_date = date(2025, 1, 12)  # ç‰¹å®šã®æ—¥ä»˜\n",
    "\n",
    "print(f\"å¯¾è±¡æ—¥: {target_date}\")\n",
    "\n",
    "# ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—\n",
    "races = scrape_race_list(target_date, jra_only=True)\n",
    "print(f\"\\n{len(races)}ä»¶ã®JRAãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "\n",
    "for race in races[:10]:\n",
    "    print(f\"  - {race['race_id']}: {race['race_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆäº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä½¿ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horse_features_batch(horse_ids: List[str]) -> Dict[str, Dict]:\n",
    "    \"\"\"è¤‡æ•°é¦¬ã®äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä¸€æ‹¬å–å¾—\"\"\"\n",
    "    if not horse_ids:\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        result = supabase.table(\"horse_features\").select(\"*\").in_(\"horse_id\", horse_ids).execute()\n",
    "        return {r[\"horse_id\"]: r for r in result.data}\n",
    "    except Exception as e:\n",
    "        print(f\"ç‰¹å¾´é‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return {}\n",
    "\n",
    "def get_jockey_features_batch(jockey_ids: List[str]) -> Dict[str, Dict]:\n",
    "    \"\"\"è¤‡æ•°é¨æ‰‹ã®äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä¸€æ‹¬å–å¾—\"\"\"\n",
    "    if not jockey_ids:\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        result = supabase.table(\"jockey_features\").select(\"*\").in_(\"jockey_id\", jockey_ids).execute()\n",
    "        return {r[\"jockey_id\"]: r for r in result.data}\n",
    "    except Exception as e:\n",
    "        print(f\"é¨æ‰‹ç‰¹å¾´é‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return {}\n",
    "\n",
    "print(\"âœ“ ç‰¹å¾´é‡å–å¾—é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_v2(race_data: Dict, horse_features: Dict, jockey_features: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã¨äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‹ã‚‰äºˆæ¸¬ç”¨ç‰¹å¾´é‡ã‚’ç”Ÿæˆ\n",
    "\n",
    "    äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ + ãƒ¬ãƒ¼ã‚¹å›ºæœ‰ç‰¹å¾´é‡ = äºˆæ¸¬ç”¨ç‰¹å¾´é‡\n",
    "    \"\"\"\n",
    "    entries = race_data.get(\"entries\", [])\n",
    "    if not entries:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    features_list = []\n",
    "    distance = race_data.get(\"distance\", 1600)\n",
    "    track_type = race_data.get(\"track_type\", \"èŠ\")\n",
    "    field_size = race_data.get(\"field_size\", len(entries))\n",
    "\n",
    "    # å­£ç¯€ç‰¹å¾´é‡\n",
    "    race_date = date.today()\n",
    "    month = race_date.month\n",
    "    season = (month % 12) // 3 + 1  # 1:å†¬, 2:æ˜¥, 3:å¤, 4:ç§‹\n",
    "\n",
    "    for entry in entries:\n",
    "        horse_id = entry.get(\"horse_id\")\n",
    "        jockey_id = entry.get(\"jockey_id\")\n",
    "\n",
    "        # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆãƒ¬ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰\n",
    "        features = {\n",
    "            \"horse_number\": entry.get(\"horse_number\"),\n",
    "            \"umaban\": entry.get(\"horse_number\"),\n",
    "            \"frame_number\": entry.get(\"frame_number\", 0),\n",
    "            \"weight\": entry.get(\"weight\", 55),\n",
    "            \"distance\": distance,\n",
    "            \"track_type\": 1 if track_type == \"èŠ\" else 0,\n",
    "            \"field_size\": field_size,\n",
    "            \"race_number\": race_data.get(\"race_number\", 1),\n",
    "            \"odds\": entry.get(\"odds\", 10),\n",
    "            \"log_odds\": np.log(entry.get(\"odds\", 10) + 1),\n",
    "            \"popularity\": entry.get(\"popularity\", 10),\n",
    "            # å­£ç¯€\n",
    "            \"season\": season,\n",
    "            \"month\": month,\n",
    "            \"is_spring\": 1 if 3 <= month <= 5 else 0,\n",
    "            \"is_summer\": 1 if 6 <= month <= 8 else 0,\n",
    "            \"is_autumn\": 1 if 9 <= month <= 11 else 0,\n",
    "            \"is_winter\": 1 if month <= 2 or month == 12 else 0,\n",
    "            \"month_sin\": np.sin(2 * np.pi * month / 12),\n",
    "            \"month_cos\": np.cos(2 * np.pi * month / 12),\n",
    "        }\n",
    "\n",
    "        # é¦¬ã®äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’è¿½åŠ \n",
    "        if horse_id and horse_id in horse_features:\n",
    "            hf = horse_features[horse_id]\n",
    "            for key in [\n",
    "                \"horse_age\", \"horse_sex\",\n",
    "                \"avg_rank_last3\", \"avg_rank_last5\", \"avg_rank_last10\", \"avg_rank_all\",\n",
    "                \"prize_3races\", \"prize_5races\", \"prize_10races\",\n",
    "                \"win_rate\", \"place_rate\", \"show_rate\", \"best_rank\", \"total_runs\",\n",
    "                \"days_since_last\", \"last_result\",\n",
    "                \"avg_last3f\", \"best_last3f\",\n",
    "                \"running_style\", \"avg_first_corner\", \"avg_last_corner\",\n",
    "                \"position_up_avg\", \"escape_rate\", \"front_rate\", \"stalker_rate\", \"closer_rate\",\n",
    "                \"avg_pace_first\", \"avg_pace_second\", \"avg_pace_diff\", \"pace_consistency\",\n",
    "                \"high_pop_win_rate\", \"high_pop_show_rate\", \"high_pop_runs\",\n",
    "                \"mid_pop_win_rate\", \"mid_pop_show_rate\", \"mid_pop_runs\",\n",
    "                \"low_pop_win_rate\", \"low_pop_show_rate\", \"low_pop_runs\",\n",
    "                \"avg_odds_when_win\",\n",
    "            ]:\n",
    "                features[key] = hf.get(key)\n",
    "\n",
    "            # è·é›¢é©æ€§ï¼ˆãƒ¬ãƒ¼ã‚¹è·é›¢ã«å¿œã˜ã¦é¸æŠï¼‰\n",
    "            if distance <= 1400:\n",
    "                features[\"distance_win_rate\"] = hf.get(\"short_win_rate\")\n",
    "                features[\"distance_runs\"] = hf.get(\"short_runs\")\n",
    "            elif distance <= 1800:\n",
    "                features[\"distance_win_rate\"] = hf.get(\"mile_win_rate\")\n",
    "                features[\"distance_runs\"] = hf.get(\"mile_runs\")\n",
    "            elif distance <= 2200:\n",
    "                features[\"distance_win_rate\"] = hf.get(\"middle_win_rate\")\n",
    "                features[\"distance_runs\"] = hf.get(\"middle_runs\")\n",
    "            else:\n",
    "                features[\"distance_win_rate\"] = hf.get(\"long_win_rate\")\n",
    "                features[\"distance_runs\"] = hf.get(\"long_runs\")\n",
    "\n",
    "            # èŠ/ãƒ€ãƒ¼ãƒˆé©æ€§\n",
    "            if track_type == \"èŠ\":\n",
    "                features[\"track_win_rate\"] = hf.get(\"turf_win_rate\")\n",
    "                features[\"track_runs\"] = hf.get(\"turf_runs\")\n",
    "            else:\n",
    "                features[\"track_win_rate\"] = hf.get(\"dirt_win_rate\")\n",
    "                features[\"track_runs\"] = hf.get(\"dirt_runs\")\n",
    "\n",
    "        # é¨æ‰‹ã®äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’è¿½åŠ \n",
    "        if jockey_id and jockey_id in jockey_features:\n",
    "            jf = jockey_features[jockey_id]\n",
    "            features[\"jockey_win_rate\"] = jf.get(\"win_rate\")\n",
    "            features[\"jockey_place_rate\"] = jf.get(\"place_rate\")\n",
    "            features[\"jockey_show_rate\"] = jf.get(\"show_rate\")\n",
    "            features[\"jockey_year_wins\"] = jf.get(\"year_wins\")\n",
    "            features[\"jockey_year_rides\"] = jf.get(\"year_rides\")\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "    df = pd.DataFrame(features_list)\n",
    "\n",
    "    # è¶³ã‚Šãªã„ç‰¹å¾´é‡ã‚’0ã§åŸ‹ã‚ã‚‹\n",
    "    for col in feature_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"âœ“ ç‰¹å¾´é‡ç”Ÿæˆé–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. äºˆæ¸¬ã®å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def predict_race_v2(race_data: Dict, horse_features: Dict, jockey_features: Dict) -> Dict:\n    \"\"\"ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆv2: äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ä½¿ç”¨ï¼‰\"\"\"\n    df = create_features_v2(race_data, horse_features, jockey_features)\n\n    if df.empty:\n        return None\n\n    # ç‰¹å¾´é‡ã‚’é¸æŠ\n    X = df[feature_columns].copy()\n    X = X.fillna(0)\n\n    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\n    X_scaled = pd.DataFrame(\n        scaler.transform(X),\n        columns=X.columns,\n        index=X.index,\n    )\n\n    # äºˆæ¸¬ï¼ˆLightGBMäºŒå€¤åˆ†é¡ã¯ç›´æ¥ç¢ºç‡ã‚’å‡ºåŠ›ï¼‰\n    probs = model.predict(X_scaled)\n\n    # ç¢ºç‡ã®æ­£è¦åŒ–ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ã§åˆè¨ˆãŒ1ã«ãªã‚‹ã‚ˆã†ã«ï¼‰\n    # â€»ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã¯ä½¿ã‚ãªã„ - LightGBMã¯æ—¢ã«ç¢ºç‡ã‚’å‡ºåŠ›ã—ã¦ã„ã‚‹ãŸã‚\n    total = probs.sum()\n    if total > 0:\n        probabilities = probs / total\n    else:\n        probabilities = probs\n\n    # çµæœã‚’æ•´å½¢\n    results = []\n    entries = race_data.get(\"entries\", [])\n\n    for i, entry in enumerate(entries):\n        odds = entry.get(\"odds\") or 10\n        prob = float(probabilities[i])\n        ev = prob * odds\n\n        results.append({\n            \"horse_number\": entry.get(\"horse_number\"),\n            \"horse_name\": entry.get(\"horse_name\", \"ä¸æ˜\"),\n            \"jockey_name\": entry.get(\"jockey_name\", \"\"),\n            \"score\": float(probs[i]),  # å…ƒã®ç¢ºç‡ã‚’ä¿æŒ\n            \"probability\": prob,\n            \"odds\": odds,\n            \"expected_value\": ev,\n            \"popularity\": entry.get(\"popularity\"),\n        })\n\n    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ\n    results.sort(key=lambda x: x[\"score\"], reverse=True)\n\n    # é †ä½ä»˜ã‘\n    for i, r in enumerate(results):\n        r[\"pred_rank\"] = i + 1\n\n    return {\n        \"race_id\": race_data[\"race_id\"],\n        \"race_name\": race_data.get(\"race_name\", \"\"),\n        \"course\": race_data.get(\"course\", \"\"),\n        \"race_number\": race_data.get(\"race_number\"),\n        \"distance\": race_data.get(\"distance\"),\n        \"track_type\": race_data.get(\"track_type\"),\n        \"predictions\": results,\n    }\n\nprint(\"âœ“ äºˆæ¸¬é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from tqdm.notebook import tqdm\n\n# Playwrightãƒšãƒ¼ã‚¸ã‚’1ã¤èµ·å‹•ã—ã¦ä½¿ã„å›ã™ï¼ˆé«˜é€ŸåŒ–ï¼‰\npage = None\nif USE_BROWSER:\n    print(\"ãƒ–ãƒ©ã‚¦ã‚¶ãƒšãƒ¼ã‚¸èµ·å‹•ä¸­...\")\n    page = get_browser_page()\n    print(\"âœ“ ãƒ–ãƒ©ã‚¦ã‚¶ãƒšãƒ¼ã‚¸èµ·å‹•å®Œäº†\")\n\n# å…¨ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬ã‚’å®Ÿè¡Œ\nall_predictions = []\n\ntry:\n    for race_info in tqdm(races, desc=\"äºˆæ¸¬å®Ÿè¡Œä¸­\"):\n        try:\n            # å‡ºé¦¬è¡¨ã‚’å–å¾—ï¼ˆpageã‚’æ¸¡ã™ï¼‰\n            race_data = scrape_shutuba(race_info[\"race_id\"], page=page)\n\n            # é¦¬IDã¨é¨æ‰‹IDã‚’åé›†\n            horse_ids = [e.get(\"horse_id\") for e in race_data.get(\"entries\", []) if e.get(\"horse_id\")]\n            jockey_ids = [e.get(\"jockey_id\") for e in race_data.get(\"entries\", []) if e.get(\"jockey_id\")]\n\n            # äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’å–å¾—\n            horse_features = get_horse_features_batch(horse_ids)\n            jockey_features = get_jockey_features_batch(jockey_ids)\n\n            # äºˆæ¸¬å®Ÿè¡Œ\n            prediction = predict_race_v2(race_data, horse_features, jockey_features)\n\n            if prediction:\n                all_predictions.append(prediction)\n\n        except Exception as e:\n            print(f\"ã‚¨ãƒ©ãƒ¼: {race_info['race_id']} - {e}\")\n\nfinally:\n    # ãƒšãƒ¼ã‚¸ã‚’é–‰ã˜ã‚‹\n    if page:\n        page.close()\n        print(\"âœ“ ãƒ–ãƒ©ã‚¦ã‚¶ãƒšãƒ¼ã‚¸çµ‚äº†\")\n\nprint(f\"\\nâœ“ {len(all_predictions)}ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. äºˆæ¸¬çµæœã®è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def display_prediction(pred: Dict, show_all: bool = False):\n    \"\"\"äºˆæ¸¬çµæœã‚’è¡¨ç¤º\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"{pred['course']} {pred.get('race_number', '')}R {pred['race_name']}\")\n    print(f\"{pred.get('track_type', '')} {pred.get('distance', '')}m\")\n    print(f\"{'='*70}\")\n    print(f\"{'äºˆæƒ³':>4} {'é¦¬ç•ª':>4} {'é¦¬å':<14} {'é¨æ‰‹':<8} {'å‹ç‡':>6} {'ã‚ªãƒƒã‚º':>6} {'æœŸå¾…å€¤':>6} {'äººæ°—':>4}\")\n    print(\"-\" * 70)\n\n    display_list = pred[\"predictions\"] if show_all else pred[\"predictions\"][:5]\n\n    for p in display_list:\n        prob_pct = (p[\"probability\"] or 0) * 100\n        odds = p.get('odds')\n        odds_str = f\"{odds:.1f}\" if odds else \"-\"\n        ev = p.get(\"expected_value\") or 0\n        pop = p.get(\"popularity\") or \"-\"\n\n        # æœŸå¾…å€¤ãƒãƒ¼ã‚¯\n        if ev >= 2.0:\n            ev_mark = \"â˜…â˜…\"\n        elif ev >= 1.5:\n            ev_mark = \"â˜…\"\n        elif ev >= 1.0:\n            ev_mark = \"â—\"\n        else:\n            ev_mark = \"\"\n\n        print(f\"{p['pred_rank']:>4} {p['horse_number']:>4} {p['horse_name']:<14} {p.get('jockey_name', '') or '':<8} {prob_pct:>5.1f}% {odds_str:>6} {ev:>5.2f}{ev_mark:<2} {pop:>4}\")\n\n# å„ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬ã‚’è¡¨ç¤º\nfor pred in all_predictions:\n    display_prediction(pred)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æœŸå¾…å€¤ãŒé«˜ã„é¦¬ã®ä¸€è¦§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æœŸå¾…å€¤ãŒé«˜ã„é¦¬ã‚’æŠ½å‡ºï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰\nEV_THRESHOLD = 1.0  # @param {type:\"number\"} æœŸå¾…å€¤ä¸‹é™\nMAX_EV = 2.0        # @param {type:\"number\"} æœŸå¾…å€¤ä¸Šé™ï¼ˆé«˜ã™ãã‚‹ç©´é¦¬ã‚’é™¤å¤–ï¼‰\nMIN_PROB = 0.05     # @param {type:\"number\"} æœ€ä½ç¢ºç‡5%ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜ï¼‰\nTOP_N_PER_RACE = 3  # @param {type:\"number\"} ãƒ¬ãƒ¼ã‚¹ã”ã¨ã®æœ€å¤§æ¨å¥¨æ•°\n\nhigh_ev_horses = []\n\nfor pred in all_predictions:\n    race_candidates = []\n    \n    for p in pred[\"predictions\"]:\n        odds = p.get(\"odds\") or 0\n        prob = p.get(\"probability\") or 0\n        ev = p.get(\"expected_value\") or 0\n        \n        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜ï¼‰\n        if ev >= EV_THRESHOLD and ev <= MAX_EV and prob >= MIN_PROB:\n            race_candidates.append({\n                \"course\": pred['course'],\n                \"race_number\": pred.get('race_number', 0),\n                \"race\": f\"{pred['course']}{pred.get('race_number', '')}R\",\n                \"race_name\": pred[\"race_name\"],\n                **p\n            })\n    \n    # ãƒ¬ãƒ¼ã‚¹ã”ã¨ã«æœŸå¾…å€¤ä¸Šä½Nä»¶ã®ã¿\n    race_candidates.sort(key=lambda x: x[\"expected_value\"], reverse=True)\n    high_ev_horses.extend(race_candidates[:TOP_N_PER_RACE])\n\n# ãƒ¬ãƒ¼ã‚¹é †ã«ã‚½ãƒ¼ãƒˆ\nhigh_ev_horses.sort(key=lambda x: (x[\"course\"], x[\"race_number\"], -x[\"expected_value\"]))\n\nprint(f\"\\næ¨å¥¨é¦¬ï¼ˆEV {EV_THRESHOLD}ã€œ{MAX_EV}ã€ç¢ºç‡{MIN_PROB*100:.0f}%ä»¥ä¸Šã€å„ãƒ¬ãƒ¼ã‚¹ä¸Šä½{TOP_N_PER_RACE}ä»¶ï¼‰: {len(high_ev_horses)}é ­\")\nprint(\"=\" * 80)\nprint(f\"{'ãƒ¬ãƒ¼ã‚¹':<12} {'é¦¬ç•ª':>4} {'é¦¬å':<14} {'å‹ç‡':>6} {'ã‚ªãƒƒã‚º':>6} {'æœŸå¾…å€¤':>6}\")\nprint(\"-\" * 80)\n\nfor h in high_ev_horses:\n    prob_pct = h[\"probability\"] * 100\n    print(f\"{h['race']:<12} {h['horse_number']:>4} {h['horse_name']:<14} {prob_pct:>5.1f}% {h['odds']:>6.1f} {h['expected_value']:>6.2f}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 9. å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹äºˆæ¸¬ï¼ˆã‚ªãƒƒã‚ºæ›´æ–°å¯¾å¿œï¼‰\n\nç‰¹å®šã®ãƒ¬ãƒ¼ã‚¹ã‚’æŒ‡å®šã—ã¦ã€æœ€æ–°ã‚ªãƒƒã‚ºã§äºˆæ¸¬ã‚’å†å®Ÿè¡Œã§ãã¾ã™ã€‚",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º\nprint(\"=== æœ¬æ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ ===\\n\")\nfor i, race in enumerate(races):\n    course = COURSE_NAMES.get(race[\"race_id\"][4:6], \"\")\n    race_num = int(race[\"race_id\"][10:12])\n    print(f\"{i+1:2d}. {course}{race_num}R: {race['race_name']} (ID: {race['race_id']})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹äºˆæ¸¬\n# ä¸Šã®ä¸€è¦§ã‹ã‚‰ç•ªå·ã‚’æŒ‡å®šã™ã‚‹ã‹ã€race_idã‚’ç›´æ¥å…¥åŠ›\nRACE_INDEX = 1  # @param {type:\"integer\"} ä¸€è¦§ã®ç•ªå·ï¼ˆ1å§‹ã¾ã‚Šï¼‰\n# ã¾ãŸã¯ç›´æ¥race_idã‚’æŒ‡å®šï¼ˆç©ºæ¬„ã®å ´åˆã¯ä¸Šã®ç•ªå·ã‚’ä½¿ç”¨ï¼‰\nRACE_ID = \"\"  # @param {type:\"string\"}\n\n# ãƒ¬ãƒ¼ã‚¹ã‚’ç‰¹å®š\nif RACE_ID:\n    target_race_id = RACE_ID\nelse:\n    if 1 <= RACE_INDEX <= len(races):\n        target_race_id = races[RACE_INDEX - 1][\"race_id\"]\n    else:\n        print(f\"ã‚¨ãƒ©ãƒ¼: ç•ªå·ã¯1ã€œ{len(races)}ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„\")\n        target_race_id = None\n\nif target_race_id:\n    print(f\"äºˆæ¸¬å¯¾è±¡: {target_race_id}\")\n    print(f\"ç¾åœ¨æ™‚åˆ»: {datetime.now().strftime('%H:%M:%S')}\")\n    print(\"-\" * 50)\n    \n    # å‡ºé¦¬è¡¨ã‚’å–å¾—ï¼ˆæœ€æ–°ã‚ªãƒƒã‚ºï¼‰\n    race_data = scrape_shutuba(target_race_id)\n    \n    # ç‰¹å¾´é‡å–å¾—\n    horse_ids = [e.get(\"horse_id\") for e in race_data.get(\"entries\", []) if e.get(\"horse_id\")]\n    jockey_ids = [e.get(\"jockey_id\") for e in race_data.get(\"entries\", []) if e.get(\"jockey_id\")]\n    hf = get_horse_features_batch(horse_ids)\n    jf = get_jockey_features_batch(jockey_ids)\n    \n    # äºˆæ¸¬å®Ÿè¡Œ\n    pred = predict_race_v2(race_data, hf, jf)\n    \n    if pred:\n        # çµæœè¡¨ç¤º\n        print(f\"\\n{'='*70}\")\n        print(f\"{pred['course']} {pred.get('race_number', '')}R {pred['race_name']}\")\n        print(f\"{pred.get('track_type', '')} {pred.get('distance', '')}m\")\n        print(f\"{'='*70}\")\n        print(f\"{'äºˆæƒ³':>4} {'é¦¬ç•ª':>4} {'é¦¬å':<14} {'å‹ç‡':>6} {'ã‚ªãƒƒã‚º':>6} {'æœŸå¾…å€¤':>6} {'äººæ°—':>4}\")\n        print(\"-\" * 70)\n        \n        for p in pred[\"predictions\"]:\n            prob_pct = (p[\"probability\"] or 0) * 100\n            odds = p.get('odds')\n            odds_str = f\"{odds:.1f}\" if odds else \"-\"\n            ev = p.get(\"expected_value\") or 0\n            pop = p.get(\"popularity\") or \"-\"\n            \n            # æ¨å¥¨ãƒãƒ¼ã‚¯ï¼ˆEV 1.0ã€œ2.0ã€ç¢ºç‡5%ä»¥ä¸Šï¼‰\n            if EV_THRESHOLD <= ev <= MAX_EV and (p.get(\"probability\") or 0) >= MIN_PROB:\n                mark = \"â˜…\"\n            else:\n                mark = \"\"\n            \n            print(f\"{p['pred_rank']:>4} {p['horse_number']:>4} {p['horse_name']:<14} {prob_pct:>5.1f}% {odds_str:>6} {ev:>5.2f}{mark:<2} {pop:>4}\")\n        \n        # æ¨å¥¨é¦¬ã®ã¿æŠ½å‡ºï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜æ¡ä»¶ï¼‰\n        recommended = [p for p in pred[\"predictions\"] \n                       if EV_THRESHOLD <= (p.get(\"expected_value\") or 0) <= MAX_EV \n                       and (p.get(\"probability\") or 0) >= MIN_PROB]\n        if recommended:\n            print(f\"\\nã€æ¨å¥¨é¦¬ï¼ˆEV {EV_THRESHOLD}ã€œ{MAX_EV}ã€ç¢ºç‡{MIN_PROB*100:.0f}%ä»¥ä¸Šï¼‰ã€‘\")\n            for p in sorted(recommended, key=lambda x: x[\"expected_value\"], reverse=True)[:TOP_N_PER_RACE]:\n                print(f\"  é¦¬ç•ª{p['horse_number']:2d} {p['horse_name']}: EV={p['expected_value']:.2f}, ã‚ªãƒƒã‚º={p['odds']:.1f}\")\n    else:\n        print(\"äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ä½¿ã„æ–¹ã¾ã¨ã‚\n",
    "\n",
    "### äº‹å‰æº–å‚™ï¼ˆé€±1å›ã€ãƒ­ãƒ¼ã‚«ãƒ«PCã§å®Ÿè¡Œï¼‰\n",
    "\n",
    "1. **ãƒ¢ãƒ‡ãƒ«å­¦ç¿’**\n",
    "   ```\n",
    "   POST /api/v1/model/retrain\n",
    "   ```\n",
    "\n",
    "2. **ãƒ¢ãƒ‡ãƒ«ã‚’Supabase Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**\n",
    "   ```\n",
    "   POST /api/v1/model/storage/upload\n",
    "   ```\n",
    "\n",
    "3. **ç‰¹å¾´é‡ã‚’Supabase DBã«åŒæœŸ**\n",
    "   ```\n",
    "   POST /api/v1/model/sync-features\n",
    "   ```\n",
    "\n",
    "### å½“æ—¥äºˆæ¸¬ï¼ˆã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼‰\n",
    "\n",
    "1. ã‚»ãƒ«1ã€œ6ã‚’å®Ÿè¡Œï¼ˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€œäºˆæ¸¬å®Ÿè¡Œï¼‰\n",
    "2. ã€ŒæœŸå¾…å€¤ãŒé«˜ã„é¦¬ã®ä¸€è¦§ã€ã§è²·ã„ç›®ã‚’ç¢ºèª\n",
    "\n",
    "### ã‚¹ãƒãƒ›ã‹ã‚‰ã®ä½¿ã„æ–¹\n",
    "\n",
    "1. Google Colabã‚¢ãƒ—ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "2. ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’é–‹ã\n",
    "3. ã€Œã™ã¹ã¦å®Ÿè¡Œã€ã§äºˆæ¸¬å®Œäº†"
   ]
  }
 ]
}
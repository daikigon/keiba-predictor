{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ç«¶é¦¬äºˆæƒ³ã‚¢ãƒ—ãƒª - å½“æ—¥äºˆæ¸¬ v2\n\n**æœ€çµ‚æ›´æ–°: 2026-01-25 19:15ï¼ˆå€‹åˆ¥ãƒ¬ãƒ¼ã‚¹äºˆæ¸¬ã«ä¸€æœ¬åŒ–ï¼‰**\n\n---\n\n**Option B: äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä½¿ç”¨**\n\n## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n\n```\nã€äº‹å‰æº–å‚™ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«PC - é€±1å›ï¼‰ã€‘\n1. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ â†’ Supabase Storage ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n2. ç‰¹å¾´é‡è¨ˆç®— â†’ Supabase DB (horse_features) ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n\nã€å½“æ—¥äºˆæ¸¬ï¼ˆã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ - ã‚¹ãƒãƒ›ã‹ã‚‰OKï¼‰ã€‘\n1. Supabase Storage ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n2. netkeiba ã‹ã‚‰å½“æ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—\n3. ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦å€‹åˆ¥äºˆæ¸¬ã‚’å®Ÿè¡Œ\n4. JRAå…¬å¼ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºã‚’å–å¾—ï¼ˆPlaywrightï¼‰\n5. äºˆæ¸¬çµæœã‚’è¡¨ç¤º\n```\n\n## ä½¿ç”¨æ–¹æ³•\n1. å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ğŸ”‘ã‹ã‚‰ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã«ä»¥ä¸‹ã‚’è¨­å®šï¼š\n   - `SUPABASE_URL`\n   - `SUPABASE_KEY`\n2. ã‚»ãƒ«ã‚’é †ç•ªã«å®Ÿè¡Œï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³1ã€œ6ï¼‰\n3. ã‚»ã‚¯ã‚·ãƒ§ãƒ³7ã§ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’æŒ‡å®šã—ã¦äºˆæ¸¬å®Ÿè¡Œ\n4. ã‚ªãƒƒã‚ºã¯ãƒ¬ãƒ¼ã‚¹ç›´å‰ã«å–å¾—ã•ã‚Œã‚‹ãŸã‚ã€ç™ºèµ°å‰ã«å®Ÿè¡Œæ¨å¥¨"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install -q supabase requests beautifulsoup4 lxml pandas numpy lightgbm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Supabaseèªè¨¼æƒ…å ±ã®è¨­å®š\ntry:\n    from google.colab import userdata\n    SUPABASE_URL = userdata.get('SUPABASE_URL') or \"https://khpoovshkhppadsirgcp.supabase.co\"\n    SUPABASE_KEY = userdata.get('SUPABASE_KEY')\n    if SUPABASE_KEY:\n        print(\"âœ“ Colabã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ\")\n    else:\n        raise Exception(\"SUPABASE_KEY not set\")\nexcept:\n    # ç›´æ¥å…¥åŠ›ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰\n    SUPABASE_URL = \"https://khpoovshkhppadsirgcp.supabase.co\"  # @param {type:\"string\"}\n    SUPABASE_KEY = \"your-service-role-key\"  # @param {type:\"string\"}\n    print(\"âš  æ‰‹å‹•å…¥åŠ›ã®èªè¨¼æƒ…å ±ã‚’ä½¿ç”¨ã—ã¾ã™\")\n\n# æ¥ç¶šãƒ†ã‚¹ãƒˆ\nfrom supabase import create_client\nsupabase = create_client(SUPABASE_URL, SUPABASE_KEY)\nprint(f\"âœ“ Supabaseæ¥ç¶š: {SUPABASE_URL[:40]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BUCKET_NAME = \"models\"\n",
    "\n",
    "def list_available_models():\n",
    "    \"\"\"åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—\"\"\"\n",
    "    try:\n",
    "        files = supabase.storage.from_(BUCKET_NAME).list()\n",
    "        models = [f[\"name\"] for f in files if f[\"name\"].endswith(\".pkl\")]\n",
    "        print(f\"åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {models}\")\n",
    "        return models\n",
    "    except Exception as e:\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return []\n",
    "\n",
    "def download_model(version: str = \"v1\"):\n",
    "    \"\"\"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\"\"\"\n",
    "    filename = f\"model_{version}.pkl\"\n",
    "    print(f\"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {filename}\")\n",
    "\n",
    "    try:\n",
    "        response = supabase.storage.from_(BUCKET_NAME).download(filename)\n",
    "        buffer = io.BytesIO(response)\n",
    "        model_data = pickle.load(buffer)\n",
    "        print(f\"âœ“ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ\")\n",
    "        print(f\"  ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {model_data.get('model_version', 'unknown')}\")\n",
    "        print(f\"  ç‰¹å¾´é‡æ•°: {len(model_data.get('feature_columns', []))}\")\n",
    "        return model_data\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}\")\n",
    "        return None\n",
    "\n",
    "# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º\n",
    "list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\nMODEL_VERSION = \"v20260113\"  # @param {type:\"string\"}\n\nmodel_data = download_model(MODEL_VERSION)\n\nif model_data:\n    model = model_data[\"model\"]\n    scaler = model_data[\"scaler\"]\n    calibrator = model_data.get(\"calibrator\")\n    feature_columns = model_data[\"feature_columns\"]\n    print(f\"\\nâœ“ ãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†ï¼ˆ{len(feature_columns)}ç‰¹å¾´é‡ï¼‰\")\nelse:\n    print(\"\\nâœ— ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n    print(\"ãƒ­ãƒ¼ã‚«ãƒ«FastAPIã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä»¶æ•°ã‚’ç¢ºèª\n",
    "try:\n",
    "    horse_result = supabase.table(\"horse_features\").select(\"id\", count=\"exact\").execute()\n",
    "    jockey_result = supabase.table(\"jockey_features\").select(\"id\", count=\"exact\").execute()\n",
    "\n",
    "    print(f\"âœ“ horse_features: {horse_result.count}ä»¶\")\n",
    "    print(f\"âœ“ jockey_features: {jockey_result.count}ä»¶\")\n",
    "\n",
    "    if horse_result.count == 0:\n",
    "        print(\"\\nâš  ç‰¹å¾´é‡ãŒåŒæœŸã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼\")\n",
    "        print(\"ãƒ­ãƒ¼ã‚«ãƒ«FastAPIã§ POST /api/v1/model/sync-features ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    print(\"Supabaseã§ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ003_horse_features.sqlï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å½“æ—¥ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import requests\nimport time\nimport re\nfrom datetime import date, datetime, timedelta\nfrom bs4 import BeautifulSoup\nfrom typing import Optional, List, Dict\n\n# ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•åŒ–è¨­å®šï¼ˆColabç”¨ï¼‰\nUSE_BROWSER = True  # @param {type:\"boolean\"} ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚ªãƒƒã‚ºã‚’å–å¾—\n\nif USE_BROWSER:\n    print(\"ãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...\")\n    \n    # google-colab-selenium: Colabå°‚ç”¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸\n    !pip install -q google-colab-selenium\n    \n    from selenium.webdriver.chrome.options import Options\n    from selenium.webdriver.common.by import By\n    from selenium.webdriver.support.ui import WebDriverWait\n    from selenium.webdriver.support import expected_conditions as EC\n    import google_colab_selenium as gs\n    \n    def get_chrome_driver():\n        \"\"\"Colabç”¨Chrome WebDriverã‚’å–å¾—ï¼ˆgoogle-colab-seleniumä½¿ç”¨ï¼‰\"\"\"\n        options = Options()\n        options.add_argument(\"--headless=new\")\n        options.add_argument(\"--no-sandbox\")\n        options.add_argument(\"--disable-dev-shm-usage\")\n        options.add_argument(\"--disable-gpu\")\n        options.add_argument(\"--window-size=1920,1080\")\n        options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n        \n        driver = gs.Chrome(options=options)\n        return driver\n    \n    def close_browser(driver):\n        \"\"\"ãƒ–ãƒ©ã‚¦ã‚¶ã‚’çµ‚äº†\"\"\"\n        if driver:\n            driver.quit()\n    \n    # å‹•ä½œç¢ºèª\n    try:\n        print(\"  ChromeDriverã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...\")\n        test_driver = get_chrome_driver()\n        test_driver.get(\"https://www.google.com\")\n        title = test_driver.title\n        test_driver.quit()\n        print(f\"âœ“ ãƒ–ãƒ©ã‚¦ã‚¶æº–å‚™å®Œäº†ï¼ˆãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸: {title}ï¼‰\")\n    except Exception as e:\n        print(f\"âš  ãƒ–ãƒ©ã‚¦ã‚¶åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}\")\n        print(\"â†’ USE_BROWSER = False ã«è¨­å®šã—ã¦APIãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™\")\n        USE_BROWSER = False\n\n# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š\nSCRAPE_INTERVAL = 1.5\nHEADERS = {\n    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\",\n    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n}\n\nJRA_COURSE_CODES = {\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\"}\nCOURSE_NAMES = {\n    \"01\": \"æœ­å¹Œ\", \"02\": \"å‡½é¤¨\", \"03\": \"ç¦å³¶\", \"04\": \"æ–°æ½Ÿ\",\n    \"05\": \"æ±äº¬\", \"06\": \"ä¸­å±±\", \"07\": \"ä¸­äº¬\", \"08\": \"äº¬éƒ½\",\n    \"09\": \"é˜ªç¥\", \"10\": \"å°å€‰\",\n}\n\nsession = requests.Session()\nsession.headers.update(HEADERS)\nlast_request_time = 0\n\ndef fetch_html(url: str) -> str:\n    global last_request_time\n    elapsed = time.time() - last_request_time\n    if elapsed < SCRAPE_INTERVAL:\n        time.sleep(SCRAPE_INTERVAL - elapsed)\n\n    response = session.get(url, timeout=30)\n    last_request_time = time.time()\n\n    if \"EUC-JP\" in response.text[:500] or \"euc-jp\" in response.text[:500].lower():\n        response.encoding = \"euc-jp\"\n    else:\n        response.encoding = response.apparent_encoding or \"utf-8\"\n\n    return response.text\n\ndef is_jra_race(race_id: str) -> bool:\n    if len(race_id) >= 6:\n        return race_id[4:6] in JRA_COURSE_CODES\n    return False\n\nprint(\"âœ“ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def scrape_race_list(target_date: date, jra_only: bool = True) -> List[Dict]:\n    \"\"\"æŒ‡å®šæ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ï¼ˆrace_list_sub.htmlã‚’ä½¿ç”¨ï¼‰\"\"\"\n    date_str = target_date.strftime(\"%Y%m%d\")\n    url = f\"https://race.netkeiba.com/top/race_list_sub.html?kaisai_date={date_str}\"\n\n    html = fetch_html(url)\n    soup = BeautifulSoup(html, \"lxml\")\n\n    races = []\n    seen_ids = set()\n\n    for link in soup.find_all(\"a\", href=True):\n        href = link.get(\"href\", \"\")\n        match = re.search(r\"race_id=(\\d{12})\", href)\n        if match:\n            race_id = match.group(1)\n            if race_id not in seen_ids:\n                if jra_only and not is_jra_race(race_id):\n                    continue\n                seen_ids.add(race_id)\n                races.append({\n                    \"race_id\": race_id,\n                    \"date\": target_date.isoformat(),\n                    \"race_name\": link.get_text(strip=True),\n                })\n\n    races.sort(key=lambda x: x[\"race_id\"])\n    return races\n\n\ndef get_odds_with_selenium(race_id: str, driver=None, max_retries: int = 2, expected_count: int = 0) -> Dict[int, Dict]:\n    \"\"\"Seleniumã§netkeibaã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã‹ã‚‰ã‚ªãƒƒã‚ºã‚’å–å¾—\n\n    Args:\n        race_id: ãƒ¬ãƒ¼ã‚¹ID\n        driver: Selenium WebDriverï¼ˆNoneã®å ´åˆã¯æ–°è¦ä½œæˆï¼‰\n        max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ2å›ï¼‰\n        expected_count: æœŸå¾…ã•ã‚Œã‚‹é ­æ•°ï¼ˆ0ã®å ´åˆã¯ãƒã‚§ãƒƒã‚¯ã—ãªã„ï¼‰\n\n    Returns:\n        é¦¬ç•ªã‚’ã‚­ãƒ¼ã¨ã—ãŸã‚ªãƒƒã‚ºã¨äººæ°—ã®è¾æ›¸\n    \"\"\"\n    close_driver = False\n    if driver is None:\n        driver = get_chrome_driver()\n        close_driver = True\n\n    url = f\"https://race.netkeiba.com/odds/index.html?race_id={race_id}&type=b1\"\n    best_result = {}\n\n    for attempt in range(max_retries):\n        try:\n            driver.get(url)\n\n            # ã‚ªãƒƒã‚ºãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ\n            try:\n                WebDriverWait(driver, 15).until(\n                    lambda d: len(d.find_elements(By.CSS_SELECTOR, \"#odds_tan_block td.Odds span\")) > 0\n                )\n            except:\n                time.sleep(2.0)\n\n            # å®‰å®šåŒ–å¾…æ©Ÿ\n            time.sleep(1.5)\n\n            result = {}\n            \n            # æ¨™æº–ã‚»ãƒ¬ã‚¯ã‚¿ã§å–å¾—\n            rows = driver.find_elements(By.CSS_SELECTOR, \"#odds_tan_block table.RaceOdds_HorseList_Table tr\")\n            if not rows:\n                rows = driver.find_elements(By.CSS_SELECTOR, \"#odds_tan_block tr\")\n\n            for row in rows:\n                try:\n                    waku_elems = row.find_elements(By.CSS_SELECTOR, \"td[class^='Waku']\")\n                    if not waku_elems:\n                        continue\n                    umaban_text = waku_elems[0].text.strip()\n                    if not umaban_text.isdigit():\n                        continue\n                    umaban = int(umaban_text)\n\n                    # ã‚ªãƒƒã‚ºå–å¾—\n                    odds_text = None\n                    odds_elem = row.find_elements(By.CSS_SELECTOR, \"td.Odds span.Odds\")\n                    if odds_elem:\n                        odds_text = odds_elem[0].text.strip()\n                    if not odds_text or odds_text in [\"---.-\", \"---\", \"\"]:\n                        odds_elem = row.find_elements(By.CSS_SELECTOR, \"td.Odds span\")\n                        if odds_elem:\n                            odds_text = odds_elem[0].text.strip()\n\n                    if odds_text and odds_text not in [\"---.-\", \"---\", \"\"]:\n                        try:\n                            pop_elem = row.find_elements(By.CSS_SELECTOR, \"td.Popular span\")\n                            popularity = None\n                            if pop_elem:\n                                pop_text = pop_elem[0].text.strip()\n                                if pop_text.isdigit():\n                                    popularity = int(pop_text)\n                            result[umaban] = {\n                                \"odds\": float(odds_text),\n                                \"popularity\": popularity,\n                            }\n                        except ValueError:\n                            pass\n                except:\n                    continue\n\n            # æœ€è‰¯ã®çµæœã‚’ä¿æŒ\n            if len(result) > len(best_result):\n                best_result = result.copy()\n\n            # æˆåŠŸåˆ¤å®šï¼š50%ä»¥ä¸Šå–å¾—ã§ããŸã‚‰OKï¼ˆãƒªãƒˆãƒ©ã‚¤ã—ãªã„ï¼‰\n            if result:\n                if expected_count > 0:\n                    coverage = len(result) / expected_count\n                    if coverage >= 0.5:\n                        return result\n                    elif attempt < max_retries - 1:\n                        # 50%æœªæº€ã®å ´åˆã®ã¿ãƒªãƒˆãƒ©ã‚¤ï¼ˆãƒ­ã‚°å‡ºåŠ›ãªã—ï¼‰\n                        time.sleep(1.5)\n                        continue\n                else:\n                    return result\n            else:\n                if attempt < max_retries - 1:\n                    time.sleep(1.5)\n\n        except Exception as e:\n            if attempt == max_retries - 1:\n                print(f\"  âœ— ã‚ªãƒƒã‚ºå–å¾—å¤±æ•—ï¼ˆ{race_id}ï¼‰: {e}\")\n\n    if close_driver:\n        driver.quit()\n\n    return best_result if best_result else {}\n\n\ndef scrape_shutuba(race_id: str, driver=None, odds_source: str = None) -> Dict:\n    \"\"\"å‡ºé¦¬è¡¨ã‚’å–å¾—ï¼ˆãƒ¬ãƒ¼ã‚¹å‰ã®ãƒ‡ãƒ¼ã‚¿ï¼‰\"\"\"\n    url = f\"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}\"\n\n    response = session.get(url, timeout=30)\n    if \"EUC-JP\" in response.text[:500] or \"euc-jp\" in response.text[:500].lower():\n        response.encoding = \"euc-jp\"\n\n    soup = BeautifulSoup(response.text, \"lxml\")\n\n    race_data = {\n        \"race_id\": race_id,\n        \"course\": COURSE_NAMES.get(race_id[4:6], \"\"),\n        \"race_number\": int(race_id[10:12]) if len(race_id) >= 12 else 0,\n    }\n\n    title_elem = soup.select_one(\".RaceName\")\n    if title_elem:\n        race_data[\"race_name\"] = title_elem.get_text(strip=True)\n\n    race_data_elem = soup.select_one(\".RaceData01\")\n    if race_data_elem:\n        text = race_data_elem.get_text()\n        distance_match = re.search(r\"(\\d+)m\", text)\n        if distance_match:\n            race_data[\"distance\"] = int(distance_match.group(1))\n        if \"èŠ\" in text:\n            race_data[\"track_type\"] = \"èŠ\"\n        elif \"ãƒ€ãƒ¼ãƒˆ\" in text or \"ãƒ€\" in text:\n            race_data[\"track_type\"] = \"ãƒ€ãƒ¼ãƒˆ\"\n\n    entries = []\n    for row in soup.select(\"tr.HorseList\"):\n        entry = parse_shutuba_row(row)\n        if entry:\n            entries.append(entry)\n\n    field_size = len(entries)\n\n    # ã‚ªãƒƒã‚ºã‚’å–å¾—\n    odds_data = {}\n    if USE_BROWSER and driver:\n        odds_data = get_odds_with_selenium(race_id, driver, expected_count=field_size)\n\n    if not odds_data:\n        print(f\"âš  ã‚ªãƒƒã‚ºå–å¾—å¤±æ•—: {race_id} - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤10.0ã‚’ä½¿ç”¨\")\n\n    # ã‚ªãƒƒã‚ºã‚’ãƒãƒ¼ã‚¸\n    for entry in entries:\n        horse_num = entry.get(\"horse_number\")\n        if horse_num and horse_num in odds_data:\n            entry[\"odds\"] = odds_data[horse_num][\"odds\"]\n            entry[\"popularity\"] = odds_data[horse_num][\"popularity\"]\n\n    race_data[\"entries\"] = entries\n    race_data[\"field_size\"] = field_size\n    return race_data\n\n\ndef parse_shutuba_row(row) -> Optional[Dict]:\n    \"\"\"å‡ºé¦¬è¡¨ã®è¡Œã‚’ãƒ‘ãƒ¼ã‚¹\"\"\"\n    entry = {}\n\n    tds = row.find_all(\"td\")\n\n    if len(tds) > 0:\n        try:\n            entry[\"frame_number\"] = int(tds[0].get_text(strip=True))\n        except:\n            pass\n\n    if len(tds) > 1:\n        try:\n            entry[\"horse_number\"] = int(tds[1].get_text(strip=True))\n        except:\n            return None\n\n    horse_link = row.select_one(\"span.HorseName a\")\n    if horse_link:\n        href = horse_link.get(\"href\", \"\")\n        match = re.search(r\"/horse/(\\d+)\", href)\n        if match:\n            entry[\"horse_id\"] = match.group(1)\n        entry[\"horse_name\"] = horse_link.get_text(strip=True)\n\n    jockey_td = row.select_one(\"td.Jockey a\")\n    if jockey_td:\n        href = jockey_td.get(\"href\", \"\")\n        match = re.search(r\"/jockey/(?:result/recent/)?(\\d+)\", href)\n        if match:\n            entry[\"jockey_id\"] = match.group(1)\n        entry[\"jockey_name\"] = jockey_td.get_text(strip=True)\n\n    if len(tds) > 5:\n        try:\n            entry[\"weight\"] = float(tds[5].get_text(strip=True))\n        except:\n            pass\n\n    return entry if entry.get(\"horse_number\") else None\n\n\nprint(\"âœ“ å‡ºé¦¬è¡¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¾è±¡æ—¥ã‚’è¨­å®š\n",
    "target_date = date.today()  # ä»Šæ—¥\n",
    "# target_date = date(2025, 1, 12)  # ç‰¹å®šã®æ—¥ä»˜\n",
    "\n",
    "print(f\"å¯¾è±¡æ—¥: {target_date}\")\n",
    "\n",
    "# ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—\n",
    "races = scrape_race_list(target_date, jra_only=True)\n",
    "print(f\"\\n{len(races)}ä»¶ã®JRAãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "\n",
    "for race in races[:10]:\n",
    "    print(f\"  - {race['race_id']}: {race['race_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç‰¹å¾´é‡ã®ç”Ÿæˆï¼ˆäº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä½¿ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horse_features_batch(horse_ids: List[str]) -> Dict[str, Dict]:\n",
    "    \"\"\"è¤‡æ•°é¦¬ã®äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä¸€æ‹¬å–å¾—\"\"\"\n",
    "    if not horse_ids:\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        result = supabase.table(\"horse_features\").select(\"*\").in_(\"horse_id\", horse_ids).execute()\n",
    "        return {r[\"horse_id\"]: r for r in result.data}\n",
    "    except Exception as e:\n",
    "        print(f\"ç‰¹å¾´é‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return {}\n",
    "\n",
    "def get_jockey_features_batch(jockey_ids: List[str]) -> Dict[str, Dict]:\n",
    "    \"\"\"è¤‡æ•°é¨æ‰‹ã®äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä¸€æ‹¬å–å¾—\"\"\"\n",
    "    if not jockey_ids:\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        result = supabase.table(\"jockey_features\").select(\"*\").in_(\"jockey_id\", jockey_ids).execute()\n",
    "        return {r[\"jockey_id\"]: r for r in result.data}\n",
    "    except Exception as e:\n",
    "        print(f\"é¨æ‰‹ç‰¹å¾´é‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return {}\n",
    "\n",
    "print(\"âœ“ ç‰¹å¾´é‡å–å¾—é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_v2(race_data: Dict, horse_features: Dict, jockey_features: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã¨äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‹ã‚‰äºˆæ¸¬ç”¨ç‰¹å¾´é‡ã‚’ç”Ÿæˆ\n",
    "\n",
    "    äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ + ãƒ¬ãƒ¼ã‚¹å›ºæœ‰ç‰¹å¾´é‡ = äºˆæ¸¬ç”¨ç‰¹å¾´é‡\n",
    "    \"\"\"\n",
    "    entries = race_data.get(\"entries\", [])\n",
    "    if not entries:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    features_list = []\n",
    "    distance = race_data.get(\"distance\", 1600)\n",
    "    track_type = race_data.get(\"track_type\", \"èŠ\")\n",
    "    field_size = race_data.get(\"field_size\", len(entries))\n",
    "\n",
    "    # å­£ç¯€ç‰¹å¾´é‡\n",
    "    race_date = date.today()\n",
    "    month = race_date.month\n",
    "    season = (month % 12) // 3 + 1  # 1:å†¬, 2:æ˜¥, 3:å¤, 4:ç§‹\n",
    "\n",
    "    for entry in entries:\n",
    "        horse_id = entry.get(\"horse_id\")\n",
    "        jockey_id = entry.get(\"jockey_id\")\n",
    "\n",
    "        # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆãƒ¬ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰\n",
    "        features = {\n",
    "            \"horse_number\": entry.get(\"horse_number\"),\n",
    "            \"umaban\": entry.get(\"horse_number\"),\n",
    "            \"frame_number\": entry.get(\"frame_number\", 0),\n",
    "            \"weight\": entry.get(\"weight\", 55),\n",
    "            \"distance\": distance,\n",
    "            \"track_type\": 1 if track_type == \"èŠ\" else 0,\n",
    "            \"field_size\": field_size,\n",
    "            \"race_number\": race_data.get(\"race_number\", 1),\n",
    "            \"odds\": entry.get(\"odds\", 10),\n",
    "            \"log_odds\": np.log(entry.get(\"odds\", 10) + 1),\n",
    "            \"popularity\": entry.get(\"popularity\", 10),\n",
    "            # å­£ç¯€\n",
    "            \"season\": season,\n",
    "            \"month\": month,\n",
    "            \"is_spring\": 1 if 3 <= month <= 5 else 0,\n",
    "            \"is_summer\": 1 if 6 <= month <= 8 else 0,\n",
    "            \"is_autumn\": 1 if 9 <= month <= 11 else 0,\n",
    "            \"is_winter\": 1 if month <= 2 or month == 12 else 0,\n",
    "            \"month_sin\": np.sin(2 * np.pi * month / 12),\n",
    "            \"month_cos\": np.cos(2 * np.pi * month / 12),\n",
    "        }\n",
    "\n",
    "        # é¦¬ã®äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’è¿½åŠ \n",
    "        if horse_id and horse_id in horse_features:\n",
    "            hf = horse_features[horse_id]\n",
    "            for key in [\n",
    "                \"horse_age\", \"horse_sex\",\n",
    "                \"avg_rank_last3\", \"avg_rank_last5\", \"avg_rank_last10\", \"avg_rank_all\",\n",
    "                \"prize_3races\", \"prize_5races\", \"prize_10races\",\n",
    "                \"win_rate\", \"place_rate\", \"show_rate\", \"best_rank\", \"total_runs\",\n",
    "                \"days_since_last\", \"last_result\",\n",
    "                \"avg_last3f\", \"best_last3f\",\n",
    "                \"running_style\", \"avg_first_corner\", \"avg_last_corner\",\n",
    "                \"position_up_avg\", \"escape_rate\", \"front_rate\", \"stalker_rate\", \"closer_rate\",\n",
    "                \"avg_pace_first\", \"avg_pace_second\", \"avg_pace_diff\", \"pace_consistency\",\n",
    "                \"high_pop_win_rate\", \"high_pop_show_rate\", \"high_pop_runs\",\n",
    "                \"mid_pop_win_rate\", \"mid_pop_show_rate\", \"mid_pop_runs\",\n",
    "                \"low_pop_win_rate\", \"low_pop_show_rate\", \"low_pop_runs\",\n",
    "                \"avg_odds_when_win\",\n",
    "            ]:\n",
    "                features[key] = hf.get(key)\n",
    "\n",
    "            # è·é›¢é©æ€§ï¼ˆãƒ¬ãƒ¼ã‚¹è·é›¢ã«å¿œã˜ã¦é¸æŠï¼‰\n",
    "            if distance <= 1400:\n",
    "                features[\"distance_win_rate\"] = hf.get(\"short_win_rate\")\n",
    "                features[\"distance_runs\"] = hf.get(\"short_runs\")\n",
    "            elif distance <= 1800:\n",
    "                features[\"distance_win_rate\"] = hf.get(\"mile_win_rate\")\n",
    "                features[\"distance_runs\"] = hf.get(\"mile_runs\")\n",
    "            elif distance <= 2200:\n",
    "                features[\"distance_win_rate\"] = hf.get(\"middle_win_rate\")\n",
    "                features[\"distance_runs\"] = hf.get(\"middle_runs\")\n",
    "            else:\n",
    "                features[\"distance_win_rate\"] = hf.get(\"long_win_rate\")\n",
    "                features[\"distance_runs\"] = hf.get(\"long_runs\")\n",
    "\n",
    "            # èŠ/ãƒ€ãƒ¼ãƒˆé©æ€§\n",
    "            if track_type == \"èŠ\":\n",
    "                features[\"track_win_rate\"] = hf.get(\"turf_win_rate\")\n",
    "                features[\"track_runs\"] = hf.get(\"turf_runs\")\n",
    "            else:\n",
    "                features[\"track_win_rate\"] = hf.get(\"dirt_win_rate\")\n",
    "                features[\"track_runs\"] = hf.get(\"dirt_runs\")\n",
    "\n",
    "        # é¨æ‰‹ã®äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ã‚’è¿½åŠ \n",
    "        if jockey_id and jockey_id in jockey_features:\n",
    "            jf = jockey_features[jockey_id]\n",
    "            features[\"jockey_win_rate\"] = jf.get(\"win_rate\")\n",
    "            features[\"jockey_place_rate\"] = jf.get(\"place_rate\")\n",
    "            features[\"jockey_show_rate\"] = jf.get(\"show_rate\")\n",
    "            features[\"jockey_year_wins\"] = jf.get(\"year_wins\")\n",
    "            features[\"jockey_year_rides\"] = jf.get(\"year_rides\")\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "    df = pd.DataFrame(features_list)\n",
    "\n",
    "    # è¶³ã‚Šãªã„ç‰¹å¾´é‡ã‚’0ã§åŸ‹ã‚ã‚‹\n",
    "    for col in feature_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"âœ“ ç‰¹å¾´é‡ç”Ÿæˆé–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. äºˆæ¸¬ã®å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def predict_race_v2(race_data: Dict, horse_features: Dict, jockey_features: Dict) -> Dict:\n    \"\"\"ãƒ¬ãƒ¼ã‚¹ã®äºˆæ¸¬ã‚’å®Ÿè¡Œï¼ˆv2: äº‹å‰è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ä½¿ç”¨ï¼‰\"\"\"\n    df = create_features_v2(race_data, horse_features, jockey_features)\n\n    if df.empty:\n        return None\n\n    # ç‰¹å¾´é‡ã‚’é¸æŠ\n    X = df[feature_columns].copy()\n    X = X.fillna(0)\n\n    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°\n    X_scaled = pd.DataFrame(\n        scaler.transform(X),\n        columns=X.columns,\n        index=X.index,\n    )\n\n    # äºˆæ¸¬ï¼ˆLightGBMäºŒå€¤åˆ†é¡ã¯ç›´æ¥ç¢ºç‡ã‚’å‡ºåŠ›ï¼‰\n    probs = model.predict(X_scaled)\n\n    # ç¢ºç‡ã®æ­£è¦åŒ–ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ã§åˆè¨ˆãŒ1ã«ãªã‚‹ã‚ˆã†ã«ï¼‰\n    # â€»ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã¯ä½¿ã‚ãªã„ - LightGBMã¯æ—¢ã«ç¢ºç‡ã‚’å‡ºåŠ›ã—ã¦ã„ã‚‹ãŸã‚\n    total = probs.sum()\n    if total > 0:\n        probabilities = probs / total\n    else:\n        probabilities = probs\n\n    # çµæœã‚’æ•´å½¢\n    results = []\n    entries = race_data.get(\"entries\", [])\n\n    for i, entry in enumerate(entries):\n        odds = entry.get(\"odds\") or 10\n        prob = float(probabilities[i])\n        ev = prob * odds\n\n        results.append({\n            \"horse_number\": entry.get(\"horse_number\"),\n            \"horse_name\": entry.get(\"horse_name\", \"ä¸æ˜\"),\n            \"jockey_name\": entry.get(\"jockey_name\", \"\"),\n            \"score\": float(probs[i]),  # å…ƒã®ç¢ºç‡ã‚’ä¿æŒ\n            \"probability\": prob,\n            \"odds\": odds,\n            \"expected_value\": ev,\n            \"popularity\": entry.get(\"popularity\"),\n        })\n\n    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ\n    results.sort(key=lambda x: x[\"score\"], reverse=True)\n\n    # é †ä½ä»˜ã‘\n    for i, r in enumerate(results):\n        r[\"pred_rank\"] = i + 1\n\n    return {\n        \"race_id\": race_data[\"race_id\"],\n        \"race_name\": race_data.get(\"race_name\", \"\"),\n        \"course\": race_data.get(\"course\", \"\"),\n        \"race_number\": race_data.get(\"race_number\"),\n        \"distance\": race_data.get(\"distance\"),\n        \"track_type\": race_data.get(\"track_type\"),\n        \"predictions\": results,\n    }\n\nprint(\"âœ“ äºˆæ¸¬é–¢æ•°ã‚’å®šç¾©ã—ã¾ã—ãŸï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 7. å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹äºˆæ¸¬ï¼ˆJRAå…¬å¼ã‚ªãƒƒã‚ºå¯¾å¿œï¼‰\n\nãƒ¬ãƒ¼ã‚¹ã‚’æŒ‡å®šã—ã¦ã€JRAå…¬å¼ã‹ã‚‰æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—ã—ã¦äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Playwright ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆJRAå…¬å¼ã‹ã‚‰ã‚ªãƒƒã‚ºå–å¾—ç”¨ï¼‰\nprint(\"Playwrightã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...\")\n\n!pip install -q playwright nest_asyncio pytz\n!playwright install chromium\n\nimport nest_asyncio\nnest_asyncio.apply()  # Colabç’°å¢ƒã§asyncioã‚’ä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹\n\nimport asyncio\nimport pytz\nfrom playwright.async_api import async_playwright\n\n# æ—¥æœ¬æ™‚é–“ï¼ˆJSTï¼‰\nJST = pytz.timezone('Asia/Tokyo')\n\n# JRAç”¨ã®å ´æ‰€ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆIDã‹ã‚‰ç«¶é¦¬å ´åã¸ã®å¤‰æ›ï¼‰\nJRA_PLACE_MAPPING = {\n    1: \"æœ­å¹Œ\", 2: \"å‡½é¤¨\", 3: \"ç¦å³¶\", 4: \"æ–°æ½Ÿ\",\n    5: \"æ±äº¬\", 6: \"ä¸­å±±\", 7: \"ä¸­äº¬\", 8: \"äº¬éƒ½\",\n    9: \"é˜ªç¥\", 10: \"å°å€‰\"\n}\n\n\nasync def get_odds_from_jra_playwright(race_id: str, max_retries: int = 3) -> Dict:\n    \"\"\"\n    Playwrightã§JRAå…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºã‚’å–å¾—ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰\n\n    Args:\n        race_id: netkeibaã®race_idï¼ˆä¾‹: 202608010801ï¼‰\n                 æ§‹é€ : [0:4]=å¹´, [4:6]=å ´æ‰€, [6:8]=é–‹å‚¬å›, [8:10]=é–‹å‚¬æ—¥, [10:12]=ãƒ¬ãƒ¼ã‚¹ç•ªå·\n        max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°\n\n    Returns:\n        {\n            \"odds\": {é¦¬ç•ª: ã‚ªãƒƒã‚º},\n            \"last_update\": JRAå´ã®æœ€çµ‚æ›´æ–°æ™‚åˆ»ï¼ˆæ–‡å­—åˆ—ï¼‰,\n            \"fetch_time\": å–å¾—å®Ÿè¡Œæ™‚åˆ»ï¼ˆdatetime, JSTï¼‰\n        }\n    \"\"\"\n    # ãƒªãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆ\n    place_code = int(race_id[4:6])\n    kai = int(race_id[6:8])\n    day = int(race_id[8:10])\n    race_num = int(race_id[10:12])\n\n    place_name = JRA_PLACE_MAPPING.get(place_code)\n    if not place_name:\n        print(f\"âš  JRA: ä¸æ˜ãªç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰: {place_code}\")\n        return {\"odds\": {}, \"last_update\": None, \"fetch_time\": datetime.now(JST)}\n\n    kaisai_name = f\"{kai}å›{place_name}{day}æ—¥\"\n    race_name = f\"{race_num}ãƒ¬ãƒ¼ã‚¹\"\n\n    print(f\"  JRAå…¬å¼ã‹ã‚‰ã‚ªãƒƒã‚ºå–å¾—ä¸­: {kaisai_name} {race_name}...\")\n\n    for attempt in range(max_retries):\n        fetch_time = datetime.now(JST)  # æ—¥æœ¬æ™‚é–“ã§è¨˜éŒ²\n        last_update = None\n        \n        try:\n            async with async_playwright() as playwright:\n                browser = await playwright.chromium.launch(headless=True)\n                context = await browser.new_context()\n                page = await context.new_page()\n                \n                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆãƒ¢ãƒã‚¤ãƒ«ç’°å¢ƒã‚’è€ƒæ…®ï¼‰\n                page.set_default_timeout(30000)\n\n                try:\n                    # JRAã‚µã‚¤ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹\n                    await page.goto(\"https://www.jra.go.jp/keiba/\", wait_until=\"domcontentloaded\")\n                    await asyncio.sleep(1.0)\n\n                    # ã‚ªãƒƒã‚ºãƒšãƒ¼ã‚¸ã¸é·ç§»\n                    await page.get_by_role(\"link\", name=\"ã‚ªãƒƒã‚º\", exact=True).click()\n                    await asyncio.sleep(1.0)\n\n                    # é–‹å‚¬é¸æŠ\n                    await page.get_by_role(\"link\", name=kaisai_name).click()\n                    await asyncio.sleep(1.0)\n\n                    # ãƒ¬ãƒ¼ã‚¹é¸æŠï¼ˆãƒšãƒ¼ã‚¸é·ç§»ã‚’å¾…æ©Ÿï¼‰\n                    async with page.expect_navigation():\n                        await page.get_by_role(\"link\", name=race_name).click()\n                    await asyncio.sleep(1.0)\n\n                    # HTMLã‚’å–å¾—ã—ã¦ãƒ‘ãƒ¼ã‚¹\n                    html = await page.content()\n                    soup = BeautifulSoup(html, \"lxml\")\n                    \n                    # ã‚ªãƒƒã‚ºæœ€çµ‚æ›´æ–°æ™‚åˆ»ã‚’æŠ½å‡ºï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰\n                    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã€Œâ—‹æ™‚â—‹åˆ†ç¾åœ¨ã€\n                    update_elem = soup.find(string=re.compile(r\"\\d+æ™‚\\d+åˆ†ç¾åœ¨\"))\n                    if update_elem:\n                        last_update = update_elem.strip()\n                    else:\n                        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ãƒ†ã‚­ã‚¹ãƒˆå†…ã®æ™‚åˆ»è¡¨è¨˜ã‚’æ¢ã™\n                        for text in soup.stripped_strings:\n                            if \"ç¾åœ¨\" in text:\n                                match = re.search(r\"(\\d+æ™‚\\d+åˆ†)\", text)\n                                if match:\n                                    last_update = text.strip()\n                                    break\n                        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ã€Œâ—‹:â—‹â—‹ç¾åœ¨ã€å½¢å¼\n                        if not last_update:\n                            update_elem = soup.find(string=re.compile(r\"\\d+:\\d+.*ç¾åœ¨\"))\n                            if update_elem:\n                                last_update = update_elem.strip()\n                    \n                    odds_df = pd.read_html(html)[0][[\"é¦¬ç•ª\", \"å˜å‹\"]]\n\n                    # è¾æ›¸å½¢å¼ã«å¤‰æ›\n                    result = {}\n                    for _, row in odds_df.iterrows():\n                        umaban = int(row[\"é¦¬ç•ª\"])\n                        odds_value = row[\"å˜å‹\"]\n                        if pd.notna(odds_value) and str(odds_value) not in [\"---\", \"å–æ¶ˆ\", \"é™¤å¤–\"]:\n                            try:\n                                result[umaban] = float(odds_value)\n                            except:\n                                pass\n\n                    if result:\n                        print(f\"  âœ“ JRAå…¬å¼ã‹ã‚‰{len(result)}é ­ã®ã‚ªãƒƒã‚ºã‚’å–å¾—\")\n                        if last_update:\n                            print(f\"  âœ“ ã‚ªãƒƒã‚ºæœ€çµ‚æ›´æ–°: {last_update}\")\n                        \n                        return {\n                            \"odds\": result,\n                            \"last_update\": last_update,\n                            \"fetch_time\": fetch_time\n                        }\n                    else:\n                        raise Exception(\"ã‚ªãƒƒã‚ºãŒ0ä»¶\")\n\n                finally:\n                    await context.close()\n                    await browser.close()\n\n        except Exception as e:\n            if attempt < max_retries - 1:\n                print(f\"  âš  JRAå–å¾—ã‚¨ãƒ©ãƒ¼ã€ãƒªãƒˆãƒ©ã‚¤ {attempt + 2}/{max_retries}: {e}\")\n                await asyncio.sleep(2.0)\n            else:\n                print(f\"  âœ— JRAå…¬å¼ã‚ªãƒƒã‚ºå–å¾—å¤±æ•—: {e}\")\n    \n    return {\"odds\": {}, \"last_update\": None, \"fetch_time\": datetime.now(JST)}\n\n\nprint(\"âœ“ Playwrightæº–å‚™å®Œäº†ï¼ˆJRAå…¬å¼ã‚ªãƒƒã‚ºå–å¾—ç”¨ï¼‰\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º\nprint(\"=== æœ¬æ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ ===\\n\")\nfor i, race in enumerate(races):\n    course = COURSE_NAMES.get(race[\"race_id\"][4:6], \"\")\n    race_num = int(race[\"race_id\"][10:12])\n    print(f\"{i+1:2d}. {course}{race_num}R: {race['race_name']} (ID: {race['race_id']})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# å€‹åˆ¥ãƒ¬ãƒ¼ã‚¹äºˆæ¸¬ï¼ˆJRAå…¬å¼ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºå–å¾—ï¼‰\n\n# æ¨å¥¨é¦¬ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶\nEV_THRESHOLD = 1.0   # æœŸå¾…å€¤ä¸‹é™\nMAX_EV = 2.0         # æœŸå¾…å€¤ä¸Šé™ï¼ˆé«˜ã™ãã‚‹ç©´é¦¬ã‚’é™¤å¤–ï¼‰\nMIN_PROB = 0.05      # æœ€ä½ç¢ºç‡5%\nTOP_N_PER_RACE = 3   # ãƒ¬ãƒ¼ã‚¹ã”ã¨ã®æœ€å¤§æ¨å¥¨æ•°\n\n# ä¸Šã®ä¸€è¦§ã‹ã‚‰ç•ªå·ã‚’æŒ‡å®šã™ã‚‹ã‹ã€race_idã‚’ç›´æ¥å…¥åŠ›\nRACE_INDEX = 1  # @param {type:\"integer\"} ä¸€è¦§ã®ç•ªå·ï¼ˆ1å§‹ã¾ã‚Šï¼‰\n# ã¾ãŸã¯ç›´æ¥race_idã‚’æŒ‡å®šï¼ˆç©ºæ¬„ã®å ´åˆã¯ä¸Šã®ç•ªå·ã‚’ä½¿ç”¨ï¼‰\nRACE_ID = \"\"  # @param {type:\"string\"}\n\n# ãƒ¬ãƒ¼ã‚¹ã‚’ç‰¹å®š\nif RACE_ID:\n    target_race_id = RACE_ID\nelse:\n    if 1 <= RACE_INDEX <= len(races):\n        target_race_id = races[RACE_INDEX - 1][\"race_id\"]\n    else:\n        print(f\"ã‚¨ãƒ©ãƒ¼: ç•ªå·ã¯1ã€œ{len(races)}ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„\")\n        target_race_id = None\n\nif target_race_id:\n    print(f\"äºˆæ¸¬å¯¾è±¡: {target_race_id}\")\n    print(f\"ç¾åœ¨æ™‚åˆ»: {datetime.now(JST).strftime('%H:%M:%S')} (JST)\")\n    print(\"-\" * 50)\n    \n    # Seleniumãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’èµ·å‹•ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰\n    selenium_driver = None\n    if USE_BROWSER:\n        print(\"ChromeDriverèµ·å‹•ä¸­...\")\n        selenium_driver = get_chrome_driver()\n        print(\"âœ“ ChromeDriverèµ·å‹•å®Œäº†\")\n    \n    try:\n        # 1. netkeibaã‹ã‚‰åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆSeleniumã§ã‚ªãƒƒã‚ºã‚‚å–å¾—ï¼‰\n        print(\"\\nnetkeibaã‹ã‚‰å‡ºé¦¬è¡¨ã‚’å–å¾—ä¸­...\")\n        race_data = scrape_shutuba(target_race_id, driver=selenium_driver)\n        \n        # netkeibaã‚ªãƒƒã‚ºã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã—ã¦ä¿å­˜\n        netkeiba_odds = {}\n        for entry in race_data.get(\"entries\", []):\n            horse_num = entry.get(\"horse_number\")\n            if horse_num and entry.get(\"odds\"):\n                netkeiba_odds[horse_num] = {\n                    \"odds\": entry.get(\"odds\"),\n                    \"popularity\": entry.get(\"popularity\")\n                }\n        \n        # 2. JRAå…¬å¼ã‹ã‚‰Playwrightã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºã‚’å–å¾—\n        print(\"\\nJRAå…¬å¼ã‹ã‚‰æœ€æ–°ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­...\")\n        jra_result = asyncio.get_event_loop().run_until_complete(\n            get_odds_from_jra_playwright(target_race_id)\n        )\n        \n        jra_odds = jra_result.get(\"odds\", {})\n        odds_last_update = jra_result.get(\"last_update\")\n        odds_fetch_time = jra_result.get(\"fetch_time\")\n        \n        # 3. ã‚ªãƒƒã‚ºã‚’ãƒãƒ¼ã‚¸ï¼ˆJRAå„ªå…ˆã€å¤±æ•—æ™‚ã¯netkeibaï¼‰\n        if jra_odds:\n            odds_source_label = \"JRAå…¬å¼\"\n            for entry in race_data.get(\"entries\", []):\n                horse_num = entry.get(\"horse_number\")\n                if horse_num and horse_num in jra_odds:\n                    entry[\"odds\"] = jra_odds[horse_num]\n            \n            # ã‚ªãƒƒã‚ºã‹ã‚‰äººæ°—ã‚’ç®—å‡º\n            entries_with_odds = [(i, e.get(\"odds\", 999)) for i, e in enumerate(race_data.get(\"entries\", []))]\n            entries_with_odds.sort(key=lambda x: x[1])\n            for rank, (idx, _) in enumerate(entries_with_odds, 1):\n                race_data[\"entries\"][idx][\"popularity\"] = rank\n            \n            print(f\"âœ“ JRAå…¬å¼ã‚ªãƒƒã‚ºã‚’ãƒãƒ¼ã‚¸å®Œäº†\")\n        elif netkeiba_odds:\n            odds_source_label = \"netkeiba\"\n            print(\"âš  JRAå…¬å¼ã‚ªãƒƒã‚ºå–å¾—å¤±æ•— - netkeibaã®ã‚ªãƒƒã‚ºã‚’ä½¿ç”¨\")\n        else:\n            odds_source_label = \"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ\"\n            print(\"âš  ã‚ªãƒƒã‚ºå–å¾—å¤±æ•— - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤10.0ã‚’ä½¿ç”¨\")\n        \n        # 4. ç‰¹å¾´é‡å–å¾—\n        horse_ids = [e.get(\"horse_id\") for e in race_data.get(\"entries\", []) if e.get(\"horse_id\")]\n        jockey_ids = [e.get(\"jockey_id\") for e in race_data.get(\"entries\", []) if e.get(\"jockey_id\")]\n        hf = get_horse_features_batch(horse_ids)\n        jf = get_jockey_features_batch(jockey_ids)\n        \n        # 5. äºˆæ¸¬å®Ÿè¡Œ\n        pred = predict_race_v2(race_data, hf, jf)\n        \n        if pred:\n            # çµæœè¡¨ç¤º\n            print(f\"\\n{'='*70}\")\n            print(f\"{pred['course']} {pred.get('race_number', '')}R {pred['race_name']}\")\n            print(f\"{pred.get('track_type', '')} {pred.get('distance', '')}m\")\n            print(f\"ã‚ªãƒƒã‚ºå–å¾—å…ƒ: {odds_source_label}\")\n            if jra_odds:\n                if odds_last_update:\n                    print(f\"ã‚ªãƒƒã‚ºæœ€çµ‚æ›´æ–°: {odds_last_update}\")\n                if odds_fetch_time:\n                    print(f\"ã‚ªãƒƒã‚ºå–å¾—æ™‚åˆ»: {odds_fetch_time.strftime('%H:%M:%S')} (JST)\")\n            print(f\"{'='*70}\")\n            print(f\"{'äºˆæƒ³':>4} {'é¦¬ç•ª':>4} {'é¦¬å':<14} {'å‹ç‡':>6} {'ã‚ªãƒƒã‚º':>6} {'æœŸå¾…å€¤':>6} {'äººæ°—':>4}\")\n            print(\"-\" * 70)\n            \n            for p in pred[\"predictions\"]:\n                prob_pct = (p[\"probability\"] or 0) * 100\n                odds = p.get('odds')\n                odds_str = f\"{odds:.1f}\" if odds else \"-\"\n                ev = p.get(\"expected_value\") or 0\n                pop = p.get(\"popularity\") or \"-\"\n                \n                # æ¨å¥¨ãƒãƒ¼ã‚¯ï¼ˆEV 1.0ã€œ2.0ã€ç¢ºç‡5%ä»¥ä¸Šï¼‰\n                if EV_THRESHOLD <= ev <= MAX_EV and (p.get(\"probability\") or 0) >= MIN_PROB:\n                    mark = \"â˜…\"\n                else:\n                    mark = \"\"\n                \n                print(f\"{p['pred_rank']:>4} {p['horse_number']:>4} {p['horse_name']:<14} {prob_pct:>5.1f}% {odds_str:>6} {ev:>5.2f}{mark:<2} {pop:>4}\")\n            \n            # æ¨å¥¨é¦¬ã®ã¿æŠ½å‡ºï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜æ¡ä»¶ï¼‰\n            recommended = [p for p in pred[\"predictions\"] \n                           if EV_THRESHOLD <= (p.get(\"expected_value\") or 0) <= MAX_EV \n                           and (p.get(\"probability\") or 0) >= MIN_PROB]\n            if recommended:\n                print(f\"\\nã€æ¨å¥¨é¦¬ï¼ˆEV {EV_THRESHOLD}ã€œ{MAX_EV}ã€ç¢ºç‡{MIN_PROB*100:.0f}%ä»¥ä¸Šï¼‰ã€‘\")\n                for p in sorted(recommended, key=lambda x: x[\"expected_value\"], reverse=True)[:TOP_N_PER_RACE]:\n                    print(f\"  é¦¬ç•ª{p['horse_number']:2d} {p['horse_name']}: EV={p['expected_value']:.2f}, ã‚ªãƒƒã‚º={p['odds']:.1f}\")\n        else:\n            print(\"äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n    \n    finally:\n        # Seleniumãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’çµ‚äº†\n        if selenium_driver:\n            selenium_driver.quit()\n            print(\"\\nâœ“ ChromeDriverçµ‚äº†\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ä½¿ã„æ–¹ã¾ã¨ã‚\n\n### äº‹å‰æº–å‚™ï¼ˆé€±1å›ã€ãƒ­ãƒ¼ã‚«ãƒ«PCã§å®Ÿè¡Œï¼‰\n\n1. **ãƒ¢ãƒ‡ãƒ«å­¦ç¿’**\n   ```\n   POST /api/v1/model/retrain\n   ```\n\n2. **ãƒ¢ãƒ‡ãƒ«ã‚’Supabase Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**\n   ```\n   POST /api/v1/model/storage/upload\n   ```\n\n3. **ç‰¹å¾´é‡ã‚’Supabase DBã«åŒæœŸ**\n   ```\n   POST /api/v1/model/sync-features\n   ```\n\n### å½“æ—¥äºˆæ¸¬ï¼ˆã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼‰\n\n1. ã‚»ãƒ«1ã€œ6ã‚’é †ç•ªã«å®Ÿè¡Œï¼ˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€œäºˆæ¸¬é–¢æ•°å®šç¾©ï¼‰\n2. ã‚»ãƒ«7ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã§å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã®ç•ªå·ã‚’ç¢ºèª\n3. `RACE_INDEX` ã‚’å¤‰æ›´ã—ã¦äºˆæ¸¬å®Ÿè¡Œ\n\n### ã‚¹ãƒãƒ›ã‹ã‚‰ã®ä½¿ã„æ–¹\n\n1. Google Colabã‚¢ãƒ—ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n2. ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’é–‹ã\n3. ã‚»ãƒ«1ã€œ6ã‚’å®Ÿè¡Œã—ã¦æº–å‚™\n4. ãƒ¬ãƒ¼ã‚¹ç™ºèµ°å‰ã«ã‚»ãƒ«7ã§äºˆæ¸¬å®Ÿè¡Œï¼ˆæœ€æ–°ã‚ªãƒƒã‚ºã§è¨ˆç®—ï¼‰"
  }
 ]
}